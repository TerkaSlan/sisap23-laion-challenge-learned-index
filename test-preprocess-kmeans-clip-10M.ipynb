{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "795dc907-a987-4f09-9c8b-ef37bc20cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "909e9518-a639-4539-aa76-c35480a8a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from li.utils import pairwise_cosine\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import sparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb873e57-e16e-40f6-9283-0308480cfbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='[%(asctime)s][%(levelname)-5.5s][%(name)-.20s] %(message)s'\n",
    ")\n",
    "LOG = logging.getLogger(__name__)\n",
    "\n",
    "def increase_max_recursion_limit():\n",
    "    \"\"\" Increases the maximum recursion limit.\n",
    "    Source: https://stackoverflow.com/a/16248113\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    import resource\n",
    "    resource.setrlimit(resource.RLIMIT_STACK, (2**29, -1))\n",
    "    sys.setrecursionlimit(10**6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd09d537-e02c-4586-95ca-b39f8a6d5fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-06 08:50:24,356][INFO ][__main__] Loading clip data\n",
      "[2023-07-06 08:52:43,466][INFO ][__main__] Loading GT\n"
     ]
    }
   ],
   "source": [
    "size = '10M'\n",
    "\"\"\"\n",
    "LOG.info(f'Loading pca32 data')\n",
    "data_path = f'data/pca32v2/{size}/dataset.h5'\n",
    "f = h5py.File(data_path, 'r')\n",
    "loaded_data = f['pca32'][:, :]\n",
    "data = pd.DataFrame(loaded_data)\n",
    "data.index += 1\n",
    "\n",
    "LOG.info(f'Loading queries')\n",
    "base_path = f'data/pca32v2/{size}/'\n",
    "queries_path = f'{base_path}/query.h5'\n",
    "f2 = h5py.File(queries_path, 'r')\n",
    "#loaded_queries = f2['emb'][:, :]\n",
    "loaded_queries = f2['pca32'][:, :]\n",
    "\"\"\"\n",
    "base_path = f'data/clip768v2/{size}/'\n",
    "queries_path = f'{base_path}/query.h5'\n",
    "f2 = h5py.File(queries_path, 'r')\n",
    "#loaded_queries = f2['emb'][:, :]\n",
    "loaded_queries_seq = f2['emb'][:, :]\n",
    "\n",
    "LOG.info(f'Loading clip data')\n",
    "data_path = f'data/clip768v2/{size}/dataset.h5'\n",
    "f = h5py.File(data_path, 'r')\n",
    "loaded_clip_data = f['emb'][:, :]\n",
    "loaded_clip_data = pd.DataFrame(loaded_clip_data)\n",
    "loaded_clip_data.index += 1\n",
    "\n",
    "LOG.info(f'Loading GT')\n",
    "gt_path = f'data/groundtruth-{size}.h5'\n",
    "f3 = h5py.File(gt_path, 'r')\n",
    "loaded_gt = f3['knns'][:, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a59a7ce6-5851-4cac-85b4-3f22d7828265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-06 08:52:44,330][INFO ][faiss.loader] Loading faiss with AVX2 support.\n",
      "[2023-07-06 08:52:44,335][INFO ][faiss.loader] Could not load library with AVX2 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\",)\n",
      "[2023-07-06 08:52:44,340][INFO ][faiss.loader] Loading faiss.\n",
      "[2023-07-06 08:52:44,379][INFO ][faiss.loader] Successfully loaded faiss.\n"
     ]
    }
   ],
   "source": [
    "from li.BaseLMI import cluster_kmeans_faiss\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32b2609b-509b-4bc9-9ee0-7ed79d9ec0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 47s, sys: 6.47 s, total: 3min 54s\n",
      "Wall time: 4min 3s\n"
     ]
    }
   ],
   "source": [
    "%time data_prep = preprocessing.normalize(loaded_clip_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "923bdfdc-807d-4e26-96d0-05f35642eef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 10s, sys: 34.8 s, total: 10min 44s\n",
      "Wall time: 11min 8s\n"
     ]
    }
   ],
   "source": [
    "%time kmeans, result = cluster_kmeans_faiss(data_prep, n_clusters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c327821-4ee9-45ee-b276-b65457352d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.6 ms, sys: 15.8 ms, total: 41.4 ms\n",
      "Wall time: 42.1 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "%time queries_prep = preprocessing.normalize(loaded_queries_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d29b44c8-b0a2-418b-acf3-2ebf13f60b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partitioning_quality(kmeans, queries, data, loaded_gt, basic_clustering):\n",
    "    \n",
    "    res = kmeans.index.search(np.array(queries).astype(np.float32), 1000)\n",
    "    \n",
    "    n_cats_covered = []\n",
    "    n_objects_covered = []\n",
    "\n",
    "    for i in tqdm(range(1000), position=0, leave=True):\n",
    "        overall_sum = 0\n",
    "        overall_objects_sum = 0\n",
    "        argsorted = res[1][i]#np.argsort(res[0][i])[::-1]\n",
    "        idx = 0\n",
    "        while overall_sum < 9:\n",
    "            overall_sum += np.sum(data.loc[loaded_gt[i][:10]].category == argsorted[idx])\n",
    "            overall_objects_sum += np.sum(basic_clustering == argsorted[idx])\n",
    "            #overall_objects_sum += np.sum(pred_positions == argsorted[idx])\n",
    "            idx += 1\n",
    "        n_cats_covered.append(idx)\n",
    "        n_objects_covered.append(overall_objects_sum)\n",
    "\n",
    "    mean_cats_covered = np.mean(np.array(n_cats_covered))\n",
    "    mean_objects_covered = np.mean(np.array(n_objects_covered))\n",
    "    LOG.info(f'mean_cats_covered={mean_cats_covered}, mean_objects_covered={mean_objects_covered}')\n",
    "    return mean_cats_covered, mean_objects_covered, np.array(n_cats_covered), np.array(n_objects_covered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bd7265f-da2b-43d1-b115-472454e79281",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(loaded_clip_data)\n",
    "data.index += 1\n",
    "data['category'] = result_wo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7758ab6-052d-4ba4-af9e-1d6028b3962d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [12:06<00:00,  1.63it/s]\n",
      "[2023-07-05 09:53:34,278][INFO ][__main__] mean_cats_covered=769.981, mean_objects_covered=81828.793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 46s, sys: 642 ms, total: 11min 47s\n",
      "Wall time: 12min 8s\n"
     ]
    }
   ],
   "source": [
    "%time mean_cats_covered, mean_objects_covered, cats_all, objs_all = get_partitioning_quality(kmeans_wo, loaded_queries_seq, data, loaded_gt, result_wo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdd50e3-b4eb-436c-af51-c6a70d2b146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_all[cats_all > 100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbc32c3c-ef7f-465e-8db4-1a909de437b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep = pd.DataFrame(data_prep)\n",
    "data_prep.index += 1\n",
    "data_prep['category'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c0bc3a5-4afc-47fc-ab0d-83707508a3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s][2023-07-05 10:23:13,399][INFO ][numexpr.utils] Note: detected 112 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "[2023-07-05 10:23:13,403][INFO ][numexpr.utils] Note: NumExpr detected 112 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "100%|██████████| 1000/1000 [02:34<00:00,  6.47it/s]\n",
      "[2023-07-05 10:25:47,858][INFO ][__main__] mean_cats_covered=5.764, mean_objects_covered=63688.211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 30s, sys: 355 ms, total: 2min 30s\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%time mean_cats_covered_prep, mean_objects_covered_prep, cat_all_prep, objs_all_prep = get_partitioning_quality(kmeans, queries_prep, data_prep, loaded_gt, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e8982dd-ca38-4924-ad88-4aa163137d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from li.model import NeuralNetwork, data_X_to_torch, data_to_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1c462a1-b1cb-4825-a85e-45b6dc1e9809",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(\n",
    "    input_dim=data_prep.drop('category', axis=1, errors='ignore').shape[1], output_dim=1000, lr=0.1, model_type='MLP'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60db86d0-32c9-4e11-ac2e-e937f41cbb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10120191, 768)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prep.drop('category', axis=1).values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70644753-5bf4-4c67-a7e3-9e1660c10090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10120191,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prep.category.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75635105-78b7-4ba8-8bbd-26825ba9603a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "class LIDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset_x, self.dataset_y = data_to_torch(\n",
    "            dataset.drop('category', axis=1).values, dataset.category.values\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_x.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset_x[idx-1], self.dataset_y[idx-1]\n",
    "        \n",
    "dataset = LIDataset(data_prep)\n",
    "        \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=256,\n",
    "    sampler=torch.utils.data.SubsetRandomSampler(data_prep.index.values.tolist())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aee22922-9581-4e97-b8c8-56c9ae7b1db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10120192"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader) * 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0be8f14a-27f3-4aee-805c-d59cf139b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20cec954-d123-4e6b-a531-1ad08c35f391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.0056, -0.0220,  0.0338,  ...,  0.0308, -0.0087,  0.0122],\n",
       "         [ 0.0525,  0.0675, -0.0280,  ...,  0.0082,  0.0393, -0.0194],\n",
       "         [ 0.0529, -0.0414, -0.0108,  ...,  0.0362,  0.0119,  0.0305],\n",
       "         ...,\n",
       "         [ 0.0080,  0.0487,  0.0260,  ..., -0.0218,  0.0243,  0.0201],\n",
       "         [ 0.0185,  0.0645, -0.0069,  ...,  0.0223, -0.0088,  0.0223],\n",
       "         [ 0.0177,  0.0296, -0.0213,  ..., -0.0275,  0.0010,  0.0159]],\n",
       "        dtype=torch.float16),\n",
       " tensor([928, 581, 367, 798, 271, 787, 706, 575, 643, 163, 554, 992, 423, 213,\n",
       "          46, 739, 267, 373, 448, 613, 377,  98, 849, 959, 985, 202, 651,  53,\n",
       "         641, 342, 509, 422, 888, 709, 154, 506, 683, 657, 920, 926, 766, 772,\n",
       "         706, 713, 286, 347, 859, 347, 407, 995, 219, 657, 694, 248, 163, 836,\n",
       "         594, 161, 212, 407,  89, 231, 386, 511, 903,  73, 931, 480, 361, 856,\n",
       "         590, 899, 387, 521, 144, 845, 780, 802, 225, 333, 222, 804,  46,  93,\n",
       "         326,  44, 606, 308,  70, 866, 289, 883, 234, 412, 861, 893, 394, 502,\n",
       "         310, 966, 953,  10, 650,   6, 455, 267, 276, 463, 735, 734, 612, 400,\n",
       "         202, 187,  73, 367, 363, 436, 328, 223, 755, 866, 858, 298, 568, 282,\n",
       "         507, 494, 815, 618, 230, 846, 949, 398, 618, 777, 813,  86,  44,   9,\n",
       "         171, 290, 164, 742, 594, 992, 456, 596, 691,  16, 130, 713, 821, 175,\n",
       "         776, 814, 478, 965, 902, 279, 148, 166, 537, 306, 289, 272, 947,   4,\n",
       "         613, 262, 197, 406, 199, 258, 928,   6, 594, 570, 298, 410, 171, 373,\n",
       "         484, 267,  52, 234, 177, 470, 269, 696, 547, 586, 396, 142, 535, 718,\n",
       "         862, 848, 110, 260, 182, 465,  81, 977, 251, 865, 350, 354, 724, 697,\n",
       "         603, 588, 825, 555, 770, 235, 688, 598, 580, 310, 337, 965, 945, 388,\n",
       "         457, 800, 265, 971, 807, 797, 591, 289, 898, 108, 375, 197, 925, 989,\n",
       "         930, 185, 902, 493, 641, 319, 200, 129, 237, 474, 101, 492, 484, 433,\n",
       "         765, 627, 416, 537])]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ceb91e17-69d1-4963-bcd8-c03d842e70fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-06 09:19:38,050][INFO ][__main__] Epochs: 1, step: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 45s, sys: 6.97 s, total: 4min 52s\n",
      "Wall time: 5min 1s\n"
     ]
    }
   ],
   "source": [
    "%time losses = nn.train_batch(train_loader, epochs=1, logger=LOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d821bfc-57f8-4152-88fa-7f7363b475d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep['category_nn'] = nn.predict(data_X_to_torch(data_prep.drop(['category'], axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7871a603-ba30-47a4-8238-53133b6ebb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 873 ms, sys: 83.8 ms, total: 957 ms\n",
      "Wall time: 982 ms\n"
     ]
    }
   ],
   "source": [
    "%time probs, classes = nn.predict_proba(data_X_to_torch(queries_prep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d22691f5-c884-42ca-94e7-933484614193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2386212c-39ef-4c53-a6f5-ba2d967ebacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([237, 237, 237, ..., 237, 237, 237])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59df2a59-6931-49b4-9d20-4c1190e7f1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([237, 707, 154, 967, 348])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = classes[:, :5][0]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5488a61-02c0-44b5-b667-10345be79dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\n",
      "237\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=10\n",
    "nns = np.zeros((queries_prep.shape[0], k), dtype=np.uint32)\n",
    "dists = np.zeros((queries_prep.shape[0], k), dtype=np.float32)\n",
    "for class_ in np.unique(classes[:, 0]):\n",
    "    print(class_)\n",
    "    cat_idxs = np.where(classes[:, 0] == class_)[0]\n",
    "    bucket_obj_indexes = data_prep.query(f'category_nn == {class_}', engine='python').index\n",
    "    seq_search_dists = pairwise_cosine(queries_prep[cat_idxs], data_prep.loc[bucket_obj_indexes].drop(['category', 'category_nn'], axis=1))\n",
    "    ann_relative = seq_search_dists.argsort()[:, :k]\n",
    "    nns[cat_idxs] = np.array(bucket_obj_indexes)[ann_relative] + 1\n",
    "    dists[cat_idxs] = np.take_along_axis(seq_search_dists, ann_relative, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "573bdc87-488e-4d52-8c3a-b36268add94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2996, 2998, 3364, 3670, 5204, 5823, 6172, 6238, 6484, 7240, 7600,\n",
       "       7678])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "457546d2-29fb-45e8-82c8-dc2bf7e62201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 2682)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_search_dists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67cd1f4b-690b-4ab8-8f9b-8b0c0bae8889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.71 s, sys: 2.34 s, total: 4.05 s\n",
      "Wall time: 4.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>category</th>\n",
       "      <th>category_nn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001982</td>\n",
       "      <td>0.043182</td>\n",
       "      <td>-0.012482</td>\n",
       "      <td>-0.042328</td>\n",
       "      <td>0.037231</td>\n",
       "      <td>0.034058</td>\n",
       "      <td>0.007252</td>\n",
       "      <td>0.026550</td>\n",
       "      <td>-0.022720</td>\n",
       "      <td>-0.038574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015549</td>\n",
       "      <td>-0.006382</td>\n",
       "      <td>-0.051208</td>\n",
       "      <td>0.016342</td>\n",
       "      <td>-0.020554</td>\n",
       "      <td>-0.008293</td>\n",
       "      <td>-0.009293</td>\n",
       "      <td>-0.024948</td>\n",
       "      <td>816</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.057281</td>\n",
       "      <td>0.052429</td>\n",
       "      <td>0.042664</td>\n",
       "      <td>0.050293</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.018616</td>\n",
       "      <td>-0.000321</td>\n",
       "      <td>-0.013687</td>\n",
       "      <td>-0.013916</td>\n",
       "      <td>0.023575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006653</td>\n",
       "      <td>0.018631</td>\n",
       "      <td>-0.061127</td>\n",
       "      <td>0.033752</td>\n",
       "      <td>-0.000931</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.018875</td>\n",
       "      <td>-0.008133</td>\n",
       "      <td>896</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.023209</td>\n",
       "      <td>-0.003998</td>\n",
       "      <td>0.005028</td>\n",
       "      <td>-0.028870</td>\n",
       "      <td>-0.004017</td>\n",
       "      <td>-0.014778</td>\n",
       "      <td>0.019791</td>\n",
       "      <td>0.014969</td>\n",
       "      <td>-0.006783</td>\n",
       "      <td>0.019745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004013</td>\n",
       "      <td>0.055695</td>\n",
       "      <td>-0.032166</td>\n",
       "      <td>0.017593</td>\n",
       "      <td>0.022995</td>\n",
       "      <td>0.027588</td>\n",
       "      <td>0.030014</td>\n",
       "      <td>-0.026230</td>\n",
       "      <td>419</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064392</td>\n",
       "      <td>0.018661</td>\n",
       "      <td>0.015472</td>\n",
       "      <td>0.004326</td>\n",
       "      <td>0.007442</td>\n",
       "      <td>0.022308</td>\n",
       "      <td>-0.017578</td>\n",
       "      <td>-0.017792</td>\n",
       "      <td>-0.008316</td>\n",
       "      <td>-0.018326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.006744</td>\n",
       "      <td>-0.013741</td>\n",
       "      <td>0.009140</td>\n",
       "      <td>0.004894</td>\n",
       "      <td>-0.005165</td>\n",
       "      <td>0.013367</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>779</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.040283</td>\n",
       "      <td>0.019684</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>-0.031708</td>\n",
       "      <td>0.042450</td>\n",
       "      <td>0.028122</td>\n",
       "      <td>-0.010551</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>-0.019608</td>\n",
       "      <td>-0.051300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026901</td>\n",
       "      <td>-0.035553</td>\n",
       "      <td>0.020477</td>\n",
       "      <td>-0.030563</td>\n",
       "      <td>-0.035278</td>\n",
       "      <td>0.006603</td>\n",
       "      <td>-0.013771</td>\n",
       "      <td>0.059387</td>\n",
       "      <td>668</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530253</th>\n",
       "      <td>0.041779</td>\n",
       "      <td>0.026520</td>\n",
       "      <td>-0.018005</td>\n",
       "      <td>-0.009857</td>\n",
       "      <td>-0.001601</td>\n",
       "      <td>0.013893</td>\n",
       "      <td>-0.012817</td>\n",
       "      <td>-0.009346</td>\n",
       "      <td>0.015144</td>\n",
       "      <td>-0.031586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004932</td>\n",
       "      <td>0.028748</td>\n",
       "      <td>-0.052185</td>\n",
       "      <td>0.023941</td>\n",
       "      <td>-0.002674</td>\n",
       "      <td>0.017761</td>\n",
       "      <td>-0.008705</td>\n",
       "      <td>-0.008926</td>\n",
       "      <td>522</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530254</th>\n",
       "      <td>0.024200</td>\n",
       "      <td>0.038208</td>\n",
       "      <td>0.009514</td>\n",
       "      <td>0.003529</td>\n",
       "      <td>0.058380</td>\n",
       "      <td>0.039551</td>\n",
       "      <td>0.021271</td>\n",
       "      <td>-0.019470</td>\n",
       "      <td>0.025757</td>\n",
       "      <td>-0.018555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007950</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>0.051025</td>\n",
       "      <td>0.048859</td>\n",
       "      <td>-0.031891</td>\n",
       "      <td>0.046509</td>\n",
       "      <td>0.065613</td>\n",
       "      <td>0.060333</td>\n",
       "      <td>334</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530255</th>\n",
       "      <td>0.030960</td>\n",
       "      <td>0.064758</td>\n",
       "      <td>-0.039032</td>\n",
       "      <td>-0.003679</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>-0.040314</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>0.011826</td>\n",
       "      <td>0.018585</td>\n",
       "      <td>-0.031586</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035339</td>\n",
       "      <td>-0.036713</td>\n",
       "      <td>0.079407</td>\n",
       "      <td>-0.010193</td>\n",
       "      <td>-0.045166</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.011749</td>\n",
       "      <td>0.026489</td>\n",
       "      <td>650</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530256</th>\n",
       "      <td>0.042297</td>\n",
       "      <td>0.044769</td>\n",
       "      <td>0.006046</td>\n",
       "      <td>0.076721</td>\n",
       "      <td>-0.030136</td>\n",
       "      <td>-0.003593</td>\n",
       "      <td>0.018723</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>-0.038605</td>\n",
       "      <td>0.006439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049286</td>\n",
       "      <td>0.015671</td>\n",
       "      <td>-0.006603</td>\n",
       "      <td>-0.032318</td>\n",
       "      <td>0.020844</td>\n",
       "      <td>-0.007820</td>\n",
       "      <td>-0.035767</td>\n",
       "      <td>0.001441</td>\n",
       "      <td>826</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530257</th>\n",
       "      <td>0.049408</td>\n",
       "      <td>0.020325</td>\n",
       "      <td>0.037842</td>\n",
       "      <td>0.047699</td>\n",
       "      <td>0.016281</td>\n",
       "      <td>0.055176</td>\n",
       "      <td>0.008423</td>\n",
       "      <td>0.016937</td>\n",
       "      <td>-0.015167</td>\n",
       "      <td>-0.045837</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035248</td>\n",
       "      <td>0.016998</td>\n",
       "      <td>0.018097</td>\n",
       "      <td>-0.009636</td>\n",
       "      <td>-0.015465</td>\n",
       "      <td>-0.014771</td>\n",
       "      <td>0.014839</td>\n",
       "      <td>-0.004829</td>\n",
       "      <td>799</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1504191 rows × 770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5         6  \\\n",
       "1       -0.001982  0.043182 -0.012482 -0.042328  0.037231  0.034058  0.007252   \n",
       "2        0.057281  0.052429  0.042664  0.050293  0.001605  0.018616 -0.000321   \n",
       "3        0.023209 -0.003998  0.005028 -0.028870 -0.004017 -0.014778  0.019791   \n",
       "4        0.064392  0.018661  0.015472  0.004326  0.007442  0.022308 -0.017578   \n",
       "5        0.040283  0.019684  0.001457 -0.031708  0.042450  0.028122 -0.010551   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "1530253  0.041779  0.026520 -0.018005 -0.009857 -0.001601  0.013893 -0.012817   \n",
       "1530254  0.024200  0.038208  0.009514  0.003529  0.058380  0.039551  0.021271   \n",
       "1530255  0.030960  0.064758 -0.039032 -0.003679  0.017166 -0.040314  0.015190   \n",
       "1530256  0.042297  0.044769  0.006046  0.076721 -0.030136 -0.003593  0.018723   \n",
       "1530257  0.049408  0.020325  0.037842  0.047699  0.016281  0.055176  0.008423   \n",
       "\n",
       "                7         8         9  ...       760       761       762  \\\n",
       "1        0.026550 -0.022720 -0.038574  ...  0.015549 -0.006382 -0.051208   \n",
       "2       -0.013687 -0.013916  0.023575  ... -0.006653  0.018631 -0.061127   \n",
       "3        0.014969 -0.006783  0.019745  ... -0.004013  0.055695 -0.032166   \n",
       "4       -0.017792 -0.008316 -0.018326  ...  0.000561  0.006744 -0.013741   \n",
       "5        0.007092 -0.019608 -0.051300  ... -0.026901 -0.035553  0.020477   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "1530253 -0.009346  0.015144 -0.031586  ...  0.004932  0.028748 -0.052185   \n",
       "1530254 -0.019470  0.025757 -0.018555  ...  0.007950  0.006348  0.051025   \n",
       "1530255  0.011826  0.018585 -0.031586  ... -0.035339 -0.036713  0.079407   \n",
       "1530256  0.002214 -0.038605  0.006439  ...  0.049286  0.015671 -0.006603   \n",
       "1530257  0.016937 -0.015167 -0.045837  ... -0.035248  0.016998  0.018097   \n",
       "\n",
       "              763       764       765       766       767  category  \\\n",
       "1        0.016342 -0.020554 -0.008293 -0.009293 -0.024948       816   \n",
       "2        0.033752 -0.000931  0.006901  0.018875 -0.008133       896   \n",
       "3        0.017593  0.022995  0.027588  0.030014 -0.026230       419   \n",
       "4        0.009140  0.004894 -0.005165  0.013367  0.006165       779   \n",
       "5       -0.030563 -0.035278  0.006603 -0.013771  0.059387       668   \n",
       "...           ...       ...       ...       ...       ...       ...   \n",
       "1530253  0.023941 -0.002674  0.017761 -0.008705 -0.008926       522   \n",
       "1530254  0.048859 -0.031891  0.046509  0.065613  0.060333       334   \n",
       "1530255 -0.010193 -0.045166  0.004787  0.011749  0.026489       650   \n",
       "1530256 -0.032318  0.020844 -0.007820 -0.035767  0.001441       826   \n",
       "1530257 -0.009636 -0.015465 -0.014771  0.014839 -0.004829       799   \n",
       "\n",
       "         category_nn  \n",
       "1                237  \n",
       "2                237  \n",
       "3                237  \n",
       "4                237  \n",
       "5                237  \n",
       "...              ...  \n",
       "1530253          237  \n",
       "1530254          237  \n",
       "1530255          237  \n",
       "1530256          237  \n",
       "1530257          237  \n",
       "\n",
       "[1504191 rows x 770 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time data_prep.query('category_nn == 237', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82ce1ca4-7017-48f1-9d08-e5eda19f26d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from li.utils import pairwise_cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b9a34-768c-4841-8e6f-5e384c019148",
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_ in classes[:, :5]:\n",
    "    dists = pairwise_cosine(\n",
    "        [queries_prep[i]],\n",
    "        data_prep.query('category_nn')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59766a6-dde7-402d-8413-1bcb1743834a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19e6d4e-e1f1-4b1d-9302-29e764a67c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "            dists = pairwise_cosine(\n",
    "                [queries[i]],\n",
    "                loaded_data_search.loc[object_ids]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e01d1fee-c746-499c-bfbf-d77311e97b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b479bc81-395e-47ba-a48d-39c8581967aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f31b23f3-6119-4e05-9769-df3da94f3a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00026137, 0.00026359, 0.00027676, 0.00027759, 0.00027917,\n",
       "       0.00027933, 0.00028126, 0.00028322, 0.00028502, 0.00028629,\n",
       "       0.00028671, 0.0002898 , 0.00029105, 0.00029117, 0.00029189,\n",
       "       0.000292  , 0.0002921 , 0.00029456, 0.00029567, 0.00029632,\n",
       "       0.00029665, 0.00029706, 0.00029716, 0.00029787, 0.00029836,\n",
       "       0.00029873, 0.00029885, 0.00029928, 0.0002996 , 0.00029967,\n",
       "       0.00030039, 0.00030062, 0.00030203, 0.00030238, 0.00030257,\n",
       "       0.00030308, 0.00030403, 0.00030452, 0.00030603, 0.00030622,\n",
       "       0.00030709, 0.00030738, 0.00030806, 0.00030844, 0.00030888,\n",
       "       0.00030912, 0.0003093 , 0.00030961, 0.00030991, 0.00031003,\n",
       "       0.00031007, 0.00031014, 0.0003102 , 0.00031084, 0.00031098,\n",
       "       0.0003127 , 0.00031299, 0.00031377, 0.00031438, 0.00031449,\n",
       "       0.00031451, 0.00031465, 0.00031499, 0.00031521, 0.00031541,\n",
       "       0.00031567, 0.00031608, 0.00031728, 0.00031731, 0.0003175 ,\n",
       "       0.00031817, 0.00031837, 0.00031958, 0.00031988, 0.00032022,\n",
       "       0.00032085, 0.00032088, 0.00032143, 0.00032161, 0.00032172,\n",
       "       0.00032255, 0.00032263, 0.00032326, 0.0003234 , 0.00032346,\n",
       "       0.00032408, 0.00032412, 0.00032438, 0.00032455, 0.00032582,\n",
       "       0.00032588, 0.00032599, 0.00032618, 0.00032625, 0.00032631,\n",
       "       0.00032702, 0.0003279 , 0.00032814, 0.00032822, 0.00032844,\n",
       "       0.00032878, 0.000329  , 0.00032906, 0.00032909, 0.00032921,\n",
       "       0.00032928, 0.00032963, 0.0003298 , 0.00033038, 0.00033073,\n",
       "       0.00033085, 0.00033125, 0.00033126, 0.00033142, 0.00033178,\n",
       "       0.00033181, 0.00033204, 0.00033234, 0.00033251, 0.00033271,\n",
       "       0.00033333, 0.00033349, 0.00033371, 0.00033372, 0.00033376,\n",
       "       0.00033392, 0.00033396, 0.00033416, 0.00033444, 0.00033446,\n",
       "       0.00033463, 0.0003348 , 0.00033485, 0.000335  , 0.00033501,\n",
       "       0.00033519, 0.0003352 , 0.00033533, 0.00033556, 0.0003358 ,\n",
       "       0.00033607, 0.00033616, 0.00033675, 0.00033692, 0.00033724,\n",
       "       0.00033754, 0.00033756, 0.00033773, 0.00033791, 0.00033794,\n",
       "       0.00033812, 0.00033827, 0.00033842, 0.00033855, 0.00033882,\n",
       "       0.00033927, 0.00033929, 0.00033944, 0.00033948, 0.00033954,\n",
       "       0.00033973, 0.00033978, 0.00034003, 0.00034026, 0.00034058,\n",
       "       0.0003407 , 0.00034115, 0.00034171, 0.00034185, 0.00034189,\n",
       "       0.00034191, 0.000342  , 0.00034209, 0.00034225, 0.00034253,\n",
       "       0.00034254, 0.00034281, 0.00034295, 0.00034313, 0.00034323,\n",
       "       0.00034334, 0.00034337, 0.00034343, 0.00034354, 0.00034355,\n",
       "       0.00034371, 0.00034373, 0.0003439 , 0.00034418, 0.00034454,\n",
       "       0.00034465, 0.00034495, 0.00034503, 0.00034589, 0.00034597,\n",
       "       0.00034603, 0.00034604, 0.00034622, 0.00034653, 0.00034656,\n",
       "       0.00034667, 0.00034678, 0.00034683, 0.00034707, 0.00034733,\n",
       "       0.00034739, 0.00034758, 0.00034761, 0.00034779, 0.00034785,\n",
       "       0.00034792, 0.00034799, 0.00034801, 0.00034807, 0.00034815,\n",
       "       0.00034825, 0.00034839, 0.00034857, 0.00034862, 0.00034872,\n",
       "       0.00034877, 0.0003491 , 0.00034915, 0.0003492 , 0.00034921,\n",
       "       0.00034977, 0.00035016, 0.0003502 , 0.00035026, 0.00035041,\n",
       "       0.00035047, 0.00035052, 0.00035052, 0.00035084, 0.0003509 ,\n",
       "       0.00035091, 0.00035092, 0.000351  , 0.00035177, 0.00035195,\n",
       "       0.00035196, 0.00035219, 0.00035241, 0.00035244, 0.00035255,\n",
       "       0.00035257, 0.00035287, 0.00035294, 0.00035302, 0.00035323,\n",
       "       0.00035366, 0.00035372, 0.00035385, 0.00035395, 0.000354  ,\n",
       "       0.00035436, 0.0003544 , 0.00035471, 0.00035484, 0.00035531,\n",
       "       0.00035532, 0.00035556, 0.00035562, 0.00035579, 0.00035586,\n",
       "       0.00035591, 0.00035592, 0.00035593, 0.00035601, 0.00035611,\n",
       "       0.00035625, 0.00035627, 0.00035639, 0.00035641, 0.00035645,\n",
       "       0.00035646, 0.00035649, 0.00035654, 0.00035666, 0.00035671,\n",
       "       0.00035676, 0.0003568 , 0.00035689, 0.00035695, 0.00035717,\n",
       "       0.00035737, 0.00035743, 0.00035757, 0.00035765, 0.00035789,\n",
       "       0.00035806, 0.0003581 , 0.00035815, 0.00035843, 0.0003585 ,\n",
       "       0.00035869, 0.00035886, 0.0003589 , 0.00035898, 0.00035909,\n",
       "       0.0003591 , 0.0003593 , 0.0003594 , 0.00035948, 0.00035964,\n",
       "       0.00035978, 0.00035989, 0.00035996, 0.00036006, 0.0003601 ,\n",
       "       0.0003602 , 0.00036037, 0.00036069, 0.00036075, 0.00036095,\n",
       "       0.00036098, 0.000361  , 0.00036101, 0.00036124, 0.00036139,\n",
       "       0.00036155, 0.00036159, 0.00036202, 0.00036241, 0.00036259,\n",
       "       0.00036267, 0.00036281, 0.00036289, 0.00036362, 0.00036444,\n",
       "       0.00036475, 0.00036478, 0.00036484, 0.00036503, 0.00036514,\n",
       "       0.00036516, 0.00036541, 0.00036543, 0.00036568, 0.0003657 ,\n",
       "       0.00036587, 0.00036598, 0.00036616, 0.00036619, 0.00036625,\n",
       "       0.0003663 , 0.00036636, 0.00036646, 0.00036671, 0.00036685,\n",
       "       0.00036688, 0.0003671 , 0.00036715, 0.00036742, 0.00036749,\n",
       "       0.00036768, 0.00036778, 0.00036785, 0.00036799, 0.000368  ,\n",
       "       0.00036801, 0.00036805, 0.00036835, 0.00036849, 0.00036859,\n",
       "       0.00036862, 0.00036871, 0.00036898, 0.00036927, 0.0003694 ,\n",
       "       0.00036946, 0.00036952, 0.00036957, 0.00036963, 0.00036991,\n",
       "       0.00037001, 0.00037003, 0.00037054, 0.00037066, 0.00037077,\n",
       "       0.00037087, 0.00037091, 0.00037111, 0.00037136, 0.00037137,\n",
       "       0.00037143, 0.00037154, 0.00037163, 0.00037168, 0.00037181,\n",
       "       0.00037199, 0.000372  , 0.00037225, 0.00037225, 0.00037232,\n",
       "       0.00037262, 0.00037262, 0.00037295, 0.00037305, 0.00037344,\n",
       "       0.00037359, 0.00037371, 0.00037389, 0.00037391, 0.00037395,\n",
       "       0.00037399, 0.00037404, 0.0003742 , 0.0003742 , 0.00037476,\n",
       "       0.00037525, 0.00037535, 0.00037558, 0.00037592, 0.0003762 ,\n",
       "       0.0003764 , 0.0003766 , 0.00037675, 0.0003768 , 0.00037685,\n",
       "       0.00037698, 0.00037733, 0.00037737, 0.00037772, 0.00037778,\n",
       "       0.00037779, 0.00037786, 0.00037793, 0.00037824, 0.00037831,\n",
       "       0.00037836, 0.00037873, 0.00037879, 0.00037889, 0.00037895,\n",
       "       0.00037898, 0.00037898, 0.00037917, 0.00037934, 0.00037938,\n",
       "       0.00037939, 0.00037943, 0.00038003, 0.00038009, 0.00038019,\n",
       "       0.00038039, 0.00038046, 0.00038058, 0.00038083, 0.00038088,\n",
       "       0.00038096, 0.0003811 , 0.0003811 , 0.00038144, 0.00038145,\n",
       "       0.00038152, 0.00038177, 0.00038182, 0.00038184, 0.00038246,\n",
       "       0.00038248, 0.00038265, 0.0003827 , 0.00038275, 0.00038296,\n",
       "       0.00038306, 0.00038319, 0.00038333, 0.00038354, 0.00038361,\n",
       "       0.00038386, 0.00038393, 0.00038395, 0.00038399, 0.00038402,\n",
       "       0.00038462, 0.00038468, 0.00038526, 0.00038546, 0.00038551,\n",
       "       0.00038563, 0.00038566, 0.00038574, 0.00038607, 0.0003862 ,\n",
       "       0.00038628, 0.00038633, 0.00038651, 0.00038652, 0.00038658,\n",
       "       0.00038659, 0.00038685, 0.00038699, 0.00038717, 0.00038718,\n",
       "       0.00038728, 0.00038741, 0.00038766, 0.00038767, 0.00038772,\n",
       "       0.00038776, 0.00038789, 0.00038824, 0.00038872, 0.00038897,\n",
       "       0.00038905, 0.00038919, 0.00038974, 0.0003901 , 0.00039013,\n",
       "       0.00039014, 0.00039026, 0.00039048, 0.00039061, 0.00039061,\n",
       "       0.00039074, 0.00039132, 0.00039145, 0.00039145, 0.00039167,\n",
       "       0.00039192, 0.00039202, 0.00039233, 0.00039244, 0.00039245,\n",
       "       0.00039247, 0.00039259, 0.00039261, 0.00039282, 0.00039349,\n",
       "       0.00039349, 0.00039352, 0.00039364, 0.00039379, 0.00039403,\n",
       "       0.00039423, 0.00039429, 0.00039468, 0.00039479, 0.00039503,\n",
       "       0.00039506, 0.00039509, 0.00039514, 0.00039543, 0.00039584,\n",
       "       0.00039592, 0.00039595, 0.00039601, 0.00039601, 0.00039623,\n",
       "       0.00039661, 0.0003967 , 0.00039707, 0.00039742, 0.00039748,\n",
       "       0.00039748, 0.0003978 , 0.00039781, 0.00039801, 0.00039825,\n",
       "       0.00039839, 0.00039842, 0.00039901, 0.00039902, 0.00039926,\n",
       "       0.00039959, 0.00039969, 0.00039989, 0.00040086, 0.00040089,\n",
       "       0.00040098, 0.0004012 , 0.0004015 , 0.00040169, 0.00040173,\n",
       "       0.00040199, 0.00040254, 0.00040258, 0.00040258, 0.00040291,\n",
       "       0.00040323, 0.00040328, 0.00040338, 0.00040418, 0.00040427,\n",
       "       0.00040444, 0.00040457, 0.00040467, 0.00040469, 0.0004048 ,\n",
       "       0.00040488, 0.00040496, 0.00040506, 0.00040508, 0.00040539,\n",
       "       0.00040541, 0.00040569, 0.00040644, 0.00040731, 0.0004074 ,\n",
       "       0.00040746, 0.00040778, 0.00040795, 0.00040802, 0.00040803,\n",
       "       0.00040806, 0.00040813, 0.00040825, 0.0004086 , 0.00040924,\n",
       "       0.00040927, 0.00040933, 0.00040943, 0.00040954, 0.00040965,\n",
       "       0.00040979, 0.00040981, 0.00040985, 0.00040999, 0.00041016,\n",
       "       0.00041076, 0.00041105, 0.00041121, 0.00041166, 0.00041168,\n",
       "       0.00041189, 0.00041223, 0.00041231, 0.00041261, 0.00041275,\n",
       "       0.00041298, 0.00041299, 0.00041332, 0.00041379, 0.00041384,\n",
       "       0.00041428, 0.00041428, 0.00041508, 0.00041536, 0.00041543,\n",
       "       0.00041556, 0.0004157 , 0.00041581, 0.00041582, 0.00041605,\n",
       "       0.00041623, 0.00041635, 0.00041674, 0.00041674, 0.00041713,\n",
       "       0.00041729, 0.00041756, 0.00041765, 0.00041767, 0.00041848,\n",
       "       0.00041927, 0.00041943, 0.00041972, 0.00041979, 0.00041982,\n",
       "       0.00042002, 0.00042051, 0.00042107, 0.00042109, 0.00042121,\n",
       "       0.00042185, 0.00042187, 0.00042195, 0.00042212, 0.00042335,\n",
       "       0.00042344, 0.00042353, 0.00042405, 0.00042412, 0.00042461,\n",
       "       0.00042478, 0.00042539, 0.0004258 , 0.00042618, 0.00042638,\n",
       "       0.00042667, 0.00042723, 0.00042786, 0.00042906, 0.00042917,\n",
       "       0.00042932, 0.00042972, 0.00042997, 0.00043017, 0.00043033,\n",
       "       0.00043071, 0.00043111, 0.00043153, 0.00043154, 0.0004322 ,\n",
       "       0.00043307, 0.00043375, 0.00043424, 0.00043425, 0.00043484,\n",
       "       0.00043499, 0.00043536, 0.00043551, 0.0004358 , 0.00043596,\n",
       "       0.00043622, 0.00043648, 0.00043662, 0.00043678, 0.00043685,\n",
       "       0.00043792, 0.0004388 , 0.00043932, 0.00043991, 0.00043998,\n",
       "       0.00044164, 0.00044202, 0.00044222, 0.00044267, 0.00044379,\n",
       "       0.00044422, 0.00044469, 0.00044486, 0.00044596, 0.0004471 ,\n",
       "       0.00044724, 0.00044797, 0.00044822, 0.00044826, 0.00044857,\n",
       "       0.0004486 , 0.00044958, 0.00044972, 0.00045016, 0.00045029,\n",
       "       0.00045194, 0.00045275, 0.00045287, 0.00045291, 0.00045323,\n",
       "       0.00045335, 0.00045479, 0.00045481, 0.00045524, 0.00045542,\n",
       "       0.00045562, 0.00045635, 0.00045681, 0.0004584 , 0.00045902,\n",
       "       0.00045919, 0.00046046, 0.00046085, 0.00046218, 0.00046474,\n",
       "       0.00046524, 0.00046677, 0.00046748, 0.00046783, 0.00047128,\n",
       "       0.00047144, 0.00047246, 0.0004734 , 0.00047603, 0.00047607,\n",
       "       0.00047676, 0.00047676, 0.00047679, 0.00047777, 0.00048048,\n",
       "       0.00048313, 0.00048524, 0.0004857 , 0.00048782, 0.00049109,\n",
       "       0.00049176, 0.00049532, 0.00049552, 0.00049729, 0.00050376,\n",
       "       0.000506  , 0.00050705, 0.00051564, 0.00052283, 0.00168424,\n",
       "       0.00191282, 0.00195512, 0.00195955, 0.00196271, 0.00198557,\n",
       "       0.00199155, 0.00199926, 0.00202483, 0.00202547, 0.00209217,\n",
       "       0.00210527, 0.00214407, 0.00214954, 0.00215078, 0.00216981,\n",
       "       0.00218629, 0.00219917, 0.00221538, 0.00223244, 0.00224616,\n",
       "       0.00226792, 0.00227985, 0.00229051, 0.00229982, 0.00231339,\n",
       "       0.00232684, 0.00233913, 0.00237466, 0.00237921, 0.00239211,\n",
       "       0.00240757, 0.00241236, 0.00242276, 0.00242363, 0.00243704,\n",
       "       0.00243959, 0.00244726, 0.00244986, 0.00245882, 0.00246798,\n",
       "       0.00248659, 0.00249295, 0.00249521, 0.00249695, 0.00249717,\n",
       "       0.00250437, 0.00251102, 0.00251246, 0.00251281, 0.00252217,\n",
       "       0.00253077, 0.00253795, 0.00254674, 0.0025536 , 0.00259313,\n",
       "       0.00261948, 0.00263603, 0.00264113, 0.00266198, 0.00266752,\n",
       "       0.00267372, 0.00267423, 0.00267793, 0.002686  , 0.00270035,\n",
       "       0.00272927, 0.00273744, 0.0027491 , 0.0027635 , 0.00276805,\n",
       "       0.00277225, 0.00278874, 0.00279174, 0.00279227, 0.00279282,\n",
       "       0.00280707, 0.00283617, 0.00285418, 0.00286002, 0.00287618,\n",
       "       0.00287985, 0.00288223, 0.00289356, 0.00289773, 0.00290775,\n",
       "       0.00290791, 0.00291269, 0.00292024, 0.00292147, 0.00292382,\n",
       "       0.00293649, 0.00295745, 0.00295808, 0.0029812 , 0.00298322,\n",
       "       0.00298372, 0.00299123, 0.00299992, 0.00300565, 0.00301666,\n",
       "       0.00302512, 0.00303634, 0.00305736, 0.00306329, 0.00306769,\n",
       "       0.00307264, 0.00307361, 0.00307538, 0.00308729, 0.00311131,\n",
       "       0.00311262, 0.00311408, 0.00311874, 0.00312619, 0.00312844,\n",
       "       0.00313343, 0.0031443 , 0.00315382, 0.0031679 , 0.00317341,\n",
       "       0.00317717, 0.00317821, 0.00319007, 0.00319184, 0.00321165,\n",
       "       0.00324644, 0.00324785, 0.00325061, 0.00325713, 0.00325827,\n",
       "       0.00327519, 0.003284  , 0.00331042, 0.00332897, 0.00333528,\n",
       "       0.00335046, 0.00335508, 0.00337669, 0.00339663, 0.00341042,\n",
       "       0.00341147, 0.00342021, 0.00344252, 0.00345101, 0.0034878 ,\n",
       "       0.0034943 , 0.00350129, 0.00352977, 0.0035328 , 0.00355806,\n",
       "       0.00357407, 0.0035807 , 0.0035873 , 0.00358817, 0.0036153 ,\n",
       "       0.00361699, 0.00362668, 0.00364646, 0.00365991, 0.00368228,\n",
       "       0.00369542, 0.00370075, 0.00371216, 0.00376341, 0.00376635,\n",
       "       0.00376676, 0.00377892, 0.00378454, 0.003818  , 0.00382321,\n",
       "       0.00382485, 0.00384555, 0.00386389, 0.00394938, 0.00395808,\n",
       "       0.00398338, 0.00404137, 0.00405188, 0.00407704, 0.00408429,\n",
       "       0.00410554, 0.00412309, 0.00414368, 0.00416533, 0.00421529,\n",
       "       0.00422419, 0.00424018, 0.00424933, 0.00426164, 0.00426373,\n",
       "       0.0042696 , 0.00439571, 0.00439844, 0.00442415, 0.00443027,\n",
       "       0.00467138, 0.00471918, 0.0047293 , 0.00481095, 0.00485198,\n",
       "       0.00486057, 0.00500766, 0.00507263, 0.0051762 , 0.00522121,\n",
       "       0.00526179, 0.00527309, 0.00532386, 0.00545688, 0.00591516,\n",
       "       0.00607289, 0.00622478, 0.00624083, 0.00679028, 0.00730976],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(probs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c19542fc-4d11-4063-b307-9c4a7e75a481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([237, 707, 154, 967, 348, 787, 467, 544, 376, 903,  27, 981,  88,\n",
       "       849, 117, 835, 207, 109, 870, 934, 143, 713, 612, 642, 979, 581,\n",
       "       751, 340, 511, 294, 645, 506, 128, 386, 304, 635, 110,  48, 373,\n",
       "       459, 123, 804, 469, 189, 859, 515, 721, 432, 778, 698, 199, 179,\n",
       "       690, 852, 130, 392, 831, 385, 122, 497, 347, 174, 488, 755, 587,\n",
       "        32, 420, 843,   4, 378, 493,  82, 580, 470, 275, 977, 907, 815,\n",
       "       966, 598, 867, 723, 886, 391, 810, 922, 957,  18, 944, 129, 389,\n",
       "       500, 817, 225, 289, 640, 227, 945, 735, 976, 228, 239, 525, 939,\n",
       "       246,  52, 404, 435, 442, 290, 142, 214, 106,  85, 523, 136, 555,\n",
       "        12, 431, 833, 648, 545, 364, 166,  37, 826, 753, 800, 316, 742,\n",
       "       369, 250,  22, 149, 436, 414, 309, 138, 700, 938, 283, 526, 359,\n",
       "       781,   9, 774, 103, 444, 438,  68, 864, 320, 725, 780, 165,  79,\n",
       "       242, 746, 446, 956, 155, 380, 229, 722, 353, 254, 534, 271,  40,\n",
       "       258, 853, 847, 899,  59,  72, 430, 226, 396, 975, 324, 487, 527,\n",
       "       524, 958, 799,  30, 311,  75, 683, 911, 819, 178,  56, 234, 417,\n",
       "       224, 678, 243, 194, 761, 338,  39, 528, 490, 390, 247, 973, 191,\n",
       "       998, 923, 308, 900, 357, 663, 252, 858, 906, 578, 766, 797, 904,\n",
       "       131, 652, 592, 278,  21, 450, 158, 694, 132, 917, 808, 895, 952,\n",
       "       801, 674, 615, 198, 741, 300, 955, 893, 697, 193, 623, 177, 280,\n",
       "        45, 182, 156, 731, 349, 631, 312, 452, 617, 827, 719, 558, 974,\n",
       "       540, 570, 521, 403, 777,  34, 606, 203, 936, 232, 816, 230, 342,\n",
       "       354, 134, 771, 621, 935, 223,  62, 857, 486, 759, 516, 332, 426,\n",
       "       393, 665,  94, 687, 409, 941, 423,   6, 762, 803, 173, 518, 482,\n",
       "       383, 210,   3, 501, 960, 724, 537, 196, 264, 661, 829, 779, 716,\n",
       "       946, 691, 988, 586, 127, 124, 205, 682, 317, 880, 948, 333, 293,\n",
       "       611, 447, 419, 560, 919, 993, 750, 145, 287,  64, 213, 968, 866,\n",
       "       251, 265,  76, 994, 468, 326, 878, 791, 846, 530, 603, 105, 499,\n",
       "       767, 163, 352, 448, 942, 757, 273, 613, 806, 962, 394, 887, 562,\n",
       "       813, 639, 728, 236,  55, 811, 932, 233, 299, 711, 909, 336, 915,\n",
       "       704, 608, 950, 161, 519, 959, 823, 607, 183,   2, 329, 675, 536,\n",
       "       912, 963, 961, 535, 949, 554, 702, 567, 498, 733, 680, 319, 775,\n",
       "       363, 940, 855, 371, 301,  41,  87, 832, 375, 334, 925, 538, 157,\n",
       "       114, 921, 795, 838, 274, 306, 451,  49, 269, 286,  20, 150, 433,\n",
       "       609, 398, 489, 133,  11, 192, 235, 218, 636,  83, 212, 802, 809,\n",
       "       897, 972, 785, 112, 387, 841, 632, 509, 559, 902,  10, 355, 477,\n",
       "       574, 277, 561,  60, 418, 520, 460,  53, 924, 628,  15, 256, 591,\n",
       "       822, 875, 888, 969, 914, 401, 159, 954, 790, 876, 176, 140, 927,\n",
       "       358,   5,  61,  29, 484, 772, 986, 464, 139, 185, 734, 471,  65,\n",
       "       160,  54, 871, 752, 197, 794, 548, 931, 476, 171, 434, 362, 845,\n",
       "       865,  51, 825, 576, 113, 588, 268, 169, 575, 107, 279, 153, 647,\n",
       "       428, 992, 765,  90, 313, 877, 754,  14, 908, 684, 400, 315, 715,\n",
       "       531, 307, 473, 551, 462, 901, 714, 812, 296, 745, 850, 619, 351,\n",
       "       119, 479, 671, 546, 860,  58, 541, 288, 747, 662, 485, 589, 272,\n",
       "       862, 756, 784, 458, 372, 204, 494, 793, 996, 170,  89, 910, 568,\n",
       "       512, 164, 706, 601, 478,   0, 990, 848, 763, 188, 677,  26, 141,\n",
       "       572, 563, 255, 472, 305, 693, 379, 637, 837, 502, 328, 201,  25,\n",
       "       367, 905, 896, 584, 481, 738,  91, 985, 209, 345, 503, 571, 889,\n",
       "       517,  35, 249, 474, 522, 291, 449, 337, 681, 118, 744, 370, 505,\n",
       "       261, 856, 284, 656, 475, 651, 692,  13, 453, 111, 186, 616, 135,\n",
       "       552,  50, 341, 295, 596,  46, 971, 397, 556, 323, 125, 407, 318,\n",
       "       594, 879, 626, 689, 148, 984, 868, 708, 676, 980, 175,  77, 543,\n",
       "       658, 736, 425, 769, 673, 590, 696, 770, 456, 729, 873, 999, 929,\n",
       "       710, 463, 796, 978, 104, 633, 266, 600, 429, 760, 565, 115, 241,\n",
       "        93, 891,  86, 727, 920, 231,  17, 995, 657, 211, 162, 789, 821,\n",
       "       465, 455, 483, 216, 807,   8, 292, 844, 918, 388, 737, 282, 937,\n",
       "       805, 539, 863, 685,  70, 507, 405, 399, 440, 828,  69, 187, 655,\n",
       "       422,  78, 654, 913, 360, 461, 965, 798,  33, 147,  16, 758, 618,\n",
       "       244, 492, 740, 595, 573, 259,  66, 926, 989, 339, 245, 382, 298,\n",
       "       529,  67, 582, 215, 202, 101, 764, 783,  95, 890, 297, 627, 686,\n",
       "       262,  74, 220, 585, 842, 547, 666, 928, 614, 421, 267, 415, 836,\n",
       "       457,  92, 699, 443, 406, 667, 330, 634, 951, 514, 144, 930, 773,\n",
       "       854, 302, 550, 206, 851, 181, 427, 953, 152,  81, 669, 820, 892,\n",
       "        38, 646,  99, 496, 622,  47, 786, 987, 510, 137, 898, 513, 605,\n",
       "        42, 597, 610, 184,  80, 964, 916, 172, 314,  28, 718, 748, 933,\n",
       "       356, 883, 695, 257, 874, 650, 557, 303, 321,   7, 732, 643, 260,\n",
       "       402, 151, 441, 970, 997, 768, 782, 668, 982, 343, 712, 146,  97,\n",
       "        96, 672, 670, 466, 222, 190, 884, 285, 219, 263, 630, 408, 872,\n",
       "       281, 424, 495, 180, 830, 776, 116, 739, 649, 381, 221, 108, 366,\n",
       "       200, 881, 411,  98, 533, 834, 991, 604,  23,  71, 331, 445, 248,\n",
       "       350,  84, 217, 553, 885,  24, 566, 599, 882, 824,  73, 549, 947,\n",
       "       310,  43, 818, 620, 653, 327,  36, 454, 410, 629, 840, 532, 583,\n",
       "       413, 270, 638, 395, 344, 701, 579,  57, 705, 365,  44, 788, 542,\n",
       "       325, 569, 120, 384, 238, 377, 839, 717, 894, 374, 126, 861,   1,\n",
       "       416, 749,  63, 943, 168, 335, 602, 641, 508,  31, 659, 660, 664,\n",
       "       593, 240, 726, 743, 869, 730, 792, 121, 720, 644, 703, 688, 195,\n",
       "       100, 814, 102, 625,  19, 439, 208, 624, 253, 361, 577, 709, 491,\n",
       "       437, 167, 322, 564, 504, 346, 983, 679, 368, 412, 480, 276])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4bcbce0-9c59-40bf-9626-e50ee7ccc23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partitioning_quality_nn(nn, queries, data, loaded_gt, basic_clustering):\n",
    "    \n",
    "    res = nn.predict_proba(data_X_to_torch(queries))\n",
    "    \n",
    "    n_cats_covered = []\n",
    "    n_objects_covered = []\n",
    "\n",
    "    for i in tqdm(range(10_000), position=0, leave=True):\n",
    "        overall_sum = 0\n",
    "        overall_objects_sum = 0\n",
    "        argsorted = np.argsort(res[0][i])[::-1]\n",
    "        idx = 0\n",
    "        while overall_sum < 9:\n",
    "            overall_sum += np.sum(data.loc[loaded_gt[i][:10]].category_nn == argsorted[idx])\n",
    "            overall_objects_sum += np.sum(basic_clustering == argsorted[idx])\n",
    "            #overall_objects_sum += np.sum(pred_positions == argsorted[idx])\n",
    "            idx += 1\n",
    "        n_cats_covered.append(idx)\n",
    "        n_objects_covered.append(overall_objects_sum)\n",
    "        if i%100 == 0 and i != 0:\n",
    "            LOG.info(f'n_cats_covered: {np.mean(np.array(n_cats_covered))}')\n",
    "            LOG.info(f'n_objects_covered: {np.mean(np.array(n_objects_covered))}')\n",
    "\n",
    "    mean_cats_covered = np.mean(np.array(n_cats_covered))\n",
    "    mean_objects_covered = np.mean(np.array(n_objects_covered))\n",
    "    LOG.info(f'mean_cats_covered={mean_cats_covered}, mean_objects_covered={mean_objects_covered}')\n",
    "    return mean_cats_covered, mean_objects_covered, np.array(n_cats_covered), np.array(n_objects_covered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0381eecb-a3d6-4873-9b6c-893497f24c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 100/10000 [00:57<1:24:14,  1.96it/s][2023-07-05 13:01:42,365][INFO ][__main__] n_cats_covered: 20.465346534653467\n",
      "[2023-07-05 13:01:42,368][INFO ][__main__] n_objects_covered: 9812007.544554455\n",
      "  2%|▏         | 200/10000 [02:00<2:11:44,  1.24it/s][2023-07-05 13:02:45,871][INFO ][__main__] n_cats_covered: 21.64676616915423\n",
      "[2023-07-05 13:02:45,876][INFO ][__main__] n_objects_covered: 9856083.268656716\n",
      "  3%|▎         | 300/10000 [03:02<2:03:19,  1.31it/s][2023-07-05 13:03:47,618][INFO ][__main__] n_cats_covered: 21.85049833887043\n",
      "[2023-07-05 13:03:47,621][INFO ][__main__] n_objects_covered: 9916437.840531562\n",
      "  3%|▎         | 306/10000 [03:05<1:24:09,  1.92it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-daf20b691e9f>\u001b[0m in \u001b[0;36mget_partitioning_quality_nn\u001b[0;34m(nn, queries, data, loaded_gt, basic_clustering)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0moverall_sum\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moverall_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloaded_gt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory_nn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0margsorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0moverall_objects_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_clustering\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0margsorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;31m#overall_objects_sum += np.sum(pred_positions == argsorted[idx])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "category_nn = nn.predict(data_X_to_torch(data_prep.drop(['category', 'category_nn'], axis=1, errors='ignore')))\n",
    "data_prep['category_nn'] = category_nn\n",
    "mean_cats_covered, mean_objects_covered, cats_all, objs_all = get_partitioning_quality_nn(nn, queries_prep, data_prep, loaded_gt, category_nn)\n",
    "mean_cats_covered, mean_objects_covered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fdb960-d3e6-45df-b36d-91cefff87843",
   "metadata": {},
   "outputs": [],
   "source": [
    "### does not seem healthy, continuing training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "49dfbac9-61b4-42f4-ba68-f927375e9e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-05 13:04:02,720][INFO ][__main__] Epochs: 10, step: 1\n",
      "[2023-07-05 13:15:55,700][INFO ][__main__] Epoch 1 | Loss 6.90045\n",
      "[2023-07-05 13:21:46,635][INFO ][__main__] Epoch 2 | Loss 6.84803\n",
      "[2023-07-05 13:27:43,067][INFO ][__main__] Epoch 3 | Loss 6.82208\n",
      "[2023-07-05 13:33:39,707][INFO ][__main__] Epoch 4 | Loss 6.79992\n",
      "[2023-07-05 13:39:37,398][INFO ][__main__] Epoch 5 | Loss 6.69049\n",
      "[2023-07-05 13:45:31,051][INFO ][__main__] Epoch 6 | Loss 6.58617\n",
      "[2023-07-05 13:51:24,429][INFO ][__main__] Epoch 7 | Loss 6.61356\n",
      "[2023-07-05 13:57:19,486][INFO ][__main__] Epoch 8 | Loss 6.48498\n",
      "[2023-07-05 14:02:30,020][INFO ][__main__] Epoch 9 | Loss 6.34543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56min 23s, sys: 22.7 s, total: 56min 46s\n",
      "Wall time: 58min 27s\n"
     ]
    }
   ],
   "source": [
    "%time losses = nn.train_batch(train_loader, epochs=10, logger=LOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fdfddc5d-7414-45b0-8e21-adbf237c9fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 100/10000 [09:03<15:41:00,  5.70s/it][2023-07-05 14:56:20,520][INFO ][__main__] n_cats_covered: 208.41584158415841\n",
      "[2023-07-05 14:56:20,524][INFO ][__main__] n_objects_covered: 9443750.376237623\n",
      "  2%|▏         | 169/10000 [15:26<18:03:31,  6.61s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-daf20b691e9f>\u001b[0m in \u001b[0;36mget_partitioning_quality_nn\u001b[0;34m(nn, queries, data, loaded_gt, basic_clustering)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0moverall_sum\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moverall_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloaded_gt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory_nn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0margsorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0moverall_objects_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_clustering\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0margsorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;31m#overall_objects_sum += np.sum(pred_positions == argsorted[idx])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "category_nn = nn.predict(data_X_to_torch(data_prep.drop(['category', 'category_nn'], axis=1, errors='ignore')))\n",
    "data_prep['category_nn'] = category_nn\n",
    "mean_cats_covered, mean_objects_covered, cats_all, objs_all = get_partitioning_quality_nn(nn, queries_prep, data_prep, loaded_gt, category_nn)\n",
    "mean_cats_covered, mean_objects_covered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2986b126-cba4-45f9-8983-aae5eb80ba51",
   "metadata": {},
   "source": [
    "data_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bf7853d7-9751-4070-a9be-51116d6c24f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999    8589934\n",
       "248     284333\n",
       "194     139088\n",
       "43      104620\n",
       "832      99259\n",
       "        ...   \n",
       "44           1\n",
       "821          1\n",
       "648          1\n",
       "941          1\n",
       "487          1\n",
       "Name: category_nn, Length: 110, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prep.category_nn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "477d4ab0-7a63-4ea6-8458-98c113fc4b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "707    28395\n",
       "716    26817\n",
       "248    26527\n",
       "965    24191\n",
       "821    24028\n",
       "       ...  \n",
       "637        3\n",
       "626        2\n",
       "844        2\n",
       "349        1\n",
       "571        1\n",
       "Name: category, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prep.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "97c29417-7597-4e1a-9000-30791dadaf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Needs more training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f77b0a6-a603-4c0b-9afa-bb10e06b6cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-05 15:05:15,612][INFO ][__main__] Epochs: 10, step: 1\n",
      "[2023-07-05 15:14:44,854][INFO ][__main__] Epoch 1 | Loss 6.44823\n",
      "[2023-07-05 15:19:23,281][INFO ][__main__] Epoch 2 | Loss 6.30594\n",
      "[2023-07-05 15:23:47,745][INFO ][__main__] Epoch 3 | Loss 6.01796\n",
      "[2023-07-05 15:28:13,252][INFO ][__main__] Epoch 4 | Loss 6.17041\n",
      "[2023-07-05 15:32:36,696][INFO ][__main__] Epoch 5 | Loss 6.14526\n",
      "[2023-07-05 15:37:09,197][INFO ][__main__] Epoch 6 | Loss 5.92167\n",
      "[2023-07-05 15:41:31,941][INFO ][__main__] Epoch 7 | Loss 5.96912\n",
      "[2023-07-05 15:45:55,760][INFO ][__main__] Epoch 8 | Loss 5.87984\n",
      "[2023-07-05 15:50:20,040][INFO ][__main__] Epoch 9 | Loss 5.53190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43min 37s, sys: 15.5 s, total: 43min 52s\n",
      "Wall time: 45min 4s\n"
     ]
    }
   ],
   "source": [
    "%time losses = nn.train_batch(train_loader, epochs=10, logger=LOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fed2842-8274-4cfb-87ef-e70b0d5eba62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([580,  84, 185,  84, 999, 987, 430, 165, 972, 538, 966, 694, 645,\n",
       "       462, 335, 209,  66, 607, 453, 828, 677, 201, 335,   1, 908,  45,\n",
       "       595, 127, 462, 944, 301,  89,  32, 567,  10, 987, 403, 791, 320,\n",
       "        27, 805,  10, 567, 629, 509, 540, 320, 908, 761, 168, 544, 351,\n",
       "       152, 183, 825, 706, 865, 795, 159, 194, 874, 932, 560,  27, 643,\n",
       "       808, 406, 696, 922, 415, 911, 496, 453, 792, 774, 647,  18, 932,\n",
       "       212, 805, 599, 739, 626, 729,   6, 795, 323, 979, 907, 329, 982,\n",
       "       788, 830, 490, 299, 352,  51, 537, 791, 379])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0041eb-b1e3-4a7b-956f-db1bbd721c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc01e6b7-d825-4cd8-9464-ae515269eb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_all_prep[cat_all_prep > 100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e68d4adc-92e1-478d-b373-d3308c4d8f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35.4671, 3448.8709)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_cats_covered_prep, mean_objects_covered_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6501ff-7425-4608-b0c2-8c9a7309df03",
   "metadata": {},
   "source": [
    "## Problem: Many \"outliers\" (== difficult objects to find knns for)\n",
    "- try a deeper structure rather than wider -> 10 cats on L1 -- can we minimize the spread of knns here?\n",
    "    - could speed up the training of NN\n",
    "- try clip instead of PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa241f6-5608-48f2-8616-5f7f30a032c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f6c512-b4aa-426c-bb2f-dc0856dc5e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c5950f-d28c-4b0c-952e-f5bed600f091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f6f6e7a-a5c2-4560-9022-37b4cc97ac2c",
   "metadata": {},
   "source": [
    "## How best to train\n",
    "- Observation: My simple MLP cannot handle 10M data (probably overloads CPU and job terminated prematurely)\n",
    "    - Solution: train iteratively with 100k subsets\n",
    "        - Problem: Takes a long time\n",
    "            - Proposed solution: Try to use just a subset of data, check train as well as validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a748bd7-1115-4165-afce-441cf6ad8edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch training wih periodic check regarding quality of the splits (similar to get_partitioning_quality, but gauging the NN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5b539e-e697-43ab-bd75-c892dac8c1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class LIDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset_x = dataset.drop('category', axis=1).values\n",
    "        self.dataset_y = dataset.category.values\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_x.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset_x[idx], self.dataset_y[idx]\n",
    "        \n",
    "dataset = LIDataset(data_prep)\n",
    "        \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=256,\n",
    "    sampler=torch.utils.data.SubsetRandomSampler(data_prep.index)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18dae28-bbe0-4cf1-a72d-9248c9623bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = iter(train_loader)\n",
    "next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5608eb05-43b1-4032-a127-7048b5b5ebd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([549, 235, 891, 693, 779, 848, 164,  51, 963, 694, 500, 932, 301,\n",
       "       213, 940, 372, 698,  94, 769, 635, 489, 849, 728, 657, 223, 103,\n",
       "       654, 143,  49, 529,  40, 716, 166, 420, 952, 291, 643, 677, 547,\n",
       "       417, 672, 682, 559, 858, 799, 496, 441, 197, 435, 199, 491, 812,\n",
       "       200, 828,  16,  56,   6,  61, 892, 738, 910, 938, 306, 374, 202,\n",
       "        42, 777, 817, 571, 130,  62, 881, 596, 843, 113, 659, 582, 125,\n",
       "       948,  69,  14, 818, 780, 376, 869, 537, 127, 416,  67, 919, 636,\n",
       "       882, 316, 353, 766, 951, 311,  63,  37, 315,  45, 252, 683, 334,\n",
       "       736, 997, 887, 332, 327, 773, 255, 342, 501, 820, 457, 832, 193,\n",
       "       759,  20, 122, 279, 811, 308, 521, 254, 169, 748,  13, 646, 150,\n",
       "       623, 266, 535, 484, 222, 606, 867, 292, 658, 317, 729, 368, 586,\n",
       "       602,  41, 705,  77, 505, 493, 357, 739,  66, 191, 558, 300, 733,\n",
       "       137, 348, 861, 390, 243, 391,  86, 815, 267, 752, 962, 715, 955,\n",
       "       661, 555, 941, 794, 908, 585, 757, 701, 168, 825, 776, 320, 343,\n",
       "       283, 870,   8, 994, 430, 971, 774, 627, 634, 791, 389, 846,  95,\n",
       "       145, 603, 689,  32, 439,  28, 495, 946, 644, 690, 625, 686, 494,\n",
       "       552, 621, 516,  11, 721, 704, 884, 231, 367, 984, 366, 187, 525,\n",
       "       800, 599,  89, 714, 784,   2, 459, 397, 428, 761, 652, 370, 991,\n",
       "        24, 905, 989, 691, 129, 681, 857, 823, 487,   4, 262, 106, 877,\n",
       "       325, 591, 173, 290, 566, 259, 383, 224, 750, 662,  78, 925, 960,\n",
       "       781, 229, 875, 478,  10, 194, 116, 622, 534, 356, 842, 375, 841,\n",
       "       968, 804, 742,  76, 954, 520, 508,  34, 650,  80, 795, 180, 476,\n",
       "        99, 246, 422, 347, 413, 324, 936, 844, 102, 856, 617, 824, 172,\n",
       "       565, 188, 873, 999, 479, 242, 361, 216, 286, 409, 481, 149, 763,\n",
       "       782, 859, 852, 140, 718, 814, 395, 630, 577, 426, 136,  72, 656,\n",
       "       696, 853, 385, 318, 588, 289, 237, 208, 139,  50, 949, 344, 486,\n",
       "       810, 888, 695, 871,  19, 326, 527, 230, 185,  54, 909,  47, 865,\n",
       "       840, 618, 355, 983, 462, 996, 468, 920, 444, 944, 350, 483, 205,\n",
       "       573, 538, 680, 641, 407, 118, 124, 384, 509, 138, 610, 544, 732,\n",
       "       915, 541, 498, 632, 533, 611, 265, 273, 629, 249, 771, 450, 697,\n",
       "       121, 115, 388, 981, 746, 866, 724, 373, 785, 488, 432, 772, 808,\n",
       "       511, 723, 238, 276, 578, 607, 830, 942,  87, 560, 284, 419, 239,\n",
       "        30, 972, 285, 307, 899, 604, 345, 601, 107, 793, 655, 563, 167,\n",
       "       637, 471, 864, 557,  33,  57, 256, 548, 499,  79, 226, 135, 458,\n",
       "        22, 513, 803, 287, 975, 190, 349, 615, 640, 647, 515,  26, 561,\n",
       "       522, 959, 967, 613, 921, 594, 147, 165, 485, 469, 215, 834, 414,\n",
       "       234, 181, 976, 105, 369, 876, 111, 943, 337, 278, 341, 797,   0,\n",
       "       624, 354, 851, 992, 411, 935, 653, 551, 236, 725, 159, 660, 567,\n",
       "       554, 807, 158, 986, 277,  58, 109, 885, 923, 196, 268, 162,  15,\n",
       "       786, 783,   1, 126,   3, 854, 379, 393, 744, 523,  39, 467,  98,\n",
       "       153, 651, 406, 688,  59, 639, 762, 465,  46, 880, 437, 813, 642,\n",
       "       583, 280, 850, 727, 258, 517, 592, 568, 424, 597,  96, 770, 816,\n",
       "       862,  75, 731, 396, 526, 669, 768, 676, 947, 670, 402, 542, 212,\n",
       "       911, 453, 144,  53, 789,  18, 175, 545, 507, 352, 957, 539,  25,\n",
       "       684,  71, 593, 431, 504, 922, 649, 321, 418, 918, 970, 734, 510,\n",
       "       805, 890, 387, 271, 579, 157, 244, 490, 765, 195, 664, 540, 245,\n",
       "       336, 228, 404, 531, 929, 514, 440, 726, 360, 620, 401, 528, 460,\n",
       "       312, 980, 451, 979, 839, 134, 581, 421, 836, 412, 737, 835, 619,\n",
       "       257, 362, 965, 708,  84, 415, 309, 146, 985, 281, 614, 333, 879,\n",
       "       466, 790, 901, 753, 427, 433,  44, 272, 141, 152, 461,  91,  65,\n",
       "       206, 398, 671, 860, 706, 179, 359, 570, 472, 987, 274, 408,  88,\n",
       "       553, 448, 740, 519,   7, 878,  48, 241, 702, 894, 906, 745, 609,\n",
       "       895, 612, 477, 631, 445, 518, 564, 201, 546, 616, 410, 443, 403,\n",
       "       764, 330, 463, 580, 449, 524, 933, 945, 569, 675, 473, 711,  64,\n",
       "       288, 717, 678, 394, 405, 665, 900, 796, 993, 898, 474, 889, 896,\n",
       "       346, 198, 595,  55, 470, 112, 339, 863, 801, 703, 626, 638, 214,\n",
       "       455, 454, 713,  36, 747, 174,  97,  23,  38,  81, 928,  68, 323,\n",
       "       250, 503, 299, 600, 912, 436, 338, 123, 438, 364, 720,  35, 874,\n",
       "       530, 177, 155, 958, 792, 211, 253, 956, 758, 556,  82, 392, 788,\n",
       "       247, 648, 294, 434, 313,  90, 536, 893, 260, 978, 707, 132, 973,\n",
       "       293, 133, 743, 219, 380, 506, 934, 883, 930, 365, 847, 939, 220,\n",
       "       210, 148, 914, 119, 183, 645, 304, 207, 543, 297, 802, 749, 377,\n",
       "       709, 218, 248, 605, 756, 303, 902, 329, 371, 608, 674, 263, 492,\n",
       "       821, 442, 730,  74, 692, 741, 587, 798, 319, 775, 931, 961, 382,\n",
       "       264, 452, 171, 562, 108, 117, 778, 456,  92, 712, 163, 685, 160,\n",
       "       340, 837, 110,  12, 240, 633, 225, 482, 998, 275, 679, 378, 663,\n",
       "       719, 114, 937, 710, 988, 322, 916, 754, 974, 700,   9,  93, 673,\n",
       "        73, 233, 358, 446, 502, 982, 668, 261, 907, 182, 760,  17, 826,\n",
       "        27, 209, 806, 314, 868, 381, 475, 142, 628, 735, 927, 722, 351,\n",
       "       667, 666, 751,  83, 838, 845, 755, 590, 161, 363, 924, 178, 480,\n",
       "       328, 184, 192, 176, 295, 221, 572, 335, 217, 120, 131, 532, 886,\n",
       "       154, 156, 104, 574, 302, 550, 100, 227, 170, 399, 296, 977, 282,\n",
       "       128, 386, 305, 822, 904, 512, 497, 819,  31, 151,  29, 969, 827,\n",
       "       913, 204, 687, 990, 953, 903, 699,  21,  85, 251, 926, 576, 189,\n",
       "        70, 598,  43, 269, 575, 232, 584, 767, 966, 855, 831, 270, 447,\n",
       "       298, 917, 400, 464, 950, 964,  60,  52, 203, 872, 429, 423, 101,\n",
       "       331, 310, 186, 589,   5, 995, 787, 829, 425, 897, 809, 833])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f992031a-b9e2-48db-b251-945a06cf8e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.16376908, -0.26283354,  0.13444653, -0.27405524, -0.08517819,\n",
       "        0.21695286,  0.17806946,  0.25665694,  0.09803253,  0.02090712,\n",
       "       -0.1490172 , -0.40555754,  0.01857678, -0.23689921,  0.11829832,\n",
       "       -0.28729078,  0.00851109, -0.18199685,  0.20004214, -0.07592768,\n",
       "       -0.02429815,  0.17020628, -0.03283008, -0.25096416, -0.00096307,\n",
       "       -0.00693814,  0.30826217,  0.13394353,  0.01870702,  0.02429006,\n",
       "        0.14889674, -0.02364473], dtype=float32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(queries_prep[0]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ead848fe-88b5-419b-824c-4a54edcaef3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.31023687, 0.39056206, 0.39874762]], dtype=float32),\n",
       " array([[848, 891, 235]]))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.index.search(np.array(queries_prep[:1]).astype(np.float32), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3f6021f5-52d1-43fe-807d-122a151f35b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([235, 235, 235, 891, 891, 848, 848, 891, 891, 848, 891, 891, 891,\n",
       "       235, 693, 625, 625, 625, 891, 549, 693, 549, 235,  94, 547, 848,\n",
       "       891, 891, 963, 625, 779, 693, 235, 963, 891, 625, 549, 891, 779,\n",
       "       848, 496, 891, 625, 489, 188, 919, 848, 301, 848, 848, 693, 683,\n",
       "       500, 891, 891,  51, 143, 693, 166, 891, 223, 625, 891, 672, 705,\n",
       "       223, 656, 891, 625, 625, 625, 625,  51,  51, 166, 698, 625, 848,\n",
       "       891, 891, 693, 143,  51, 848, 683, 693, 549, 891, 848, 848, 848,\n",
       "       301, 891, 891, 891,  51, 848, 683, 875, 869])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[loaded_gt[0] - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "dbfd44b2-60ac-4d29-8c81-4983fd6c6d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([79171, 15734, 22336,   230, 74172, 41078, 38158, 71848, 69014,\n",
       "       92810, 99972, 79895, 13235, 64155, 86178, 55217, 60621, 64727,\n",
       "       86340, 63838, 52856,   884, 83735, 87456, 36441, 24313, 73878,\n",
       "        5984, 20969, 60558,  5413, 26293, 42585, 41369, 22972,  4414,\n",
       "       23974, 82380, 15424, 79752, 19744, 74572, 40381,  8734, 70296,\n",
       "       23883, 92500, 66708, 91231, 61307, 94072,  4326, 25524,  7179,\n",
       "       12400,  5450, 59682, 17543, 53817, 52101, 85601,   897, 76552,\n",
       "       18966, 37888, 50122, 80242, 35692, 73073, 31648, 55411, 13492,\n",
       "       67225, 21471, 81543, 70032, 91178, 97386, 94425, 76537, 64252,\n",
       "       29032, 87036, 38032, 80912, 70409, 83587, 44951,  6910, 65793,\n",
       "       45783,  5491, 35204, 21689, 16710, 95027, 19960,  1707, 68449,\n",
       "       20332], dtype=int32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_gt[0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ddb3eaa1-0175-40a0-aa3f-1510c0efef89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06877425, -0.11037602,  0.05646035, -0.11508854, -0.03577028,\n",
       "        0.09110859,  0.07477964,  0.10778218,  0.04116842,  0.00877987,\n",
       "       -0.06257925, -0.17031246,  0.00780125, -0.099485  ,  0.04967897,\n",
       "       -0.12064676,  0.0035742 , -0.07642894,  0.08400699, -0.03188556,\n",
       "       -0.01020392,  0.07147753, -0.01378688, -0.10539152, -0.00040444,\n",
       "       -0.00291365,  0.12945361,  0.05624911,  0.00785595,  0.01020052,\n",
       "        0.06252866, -0.00992952], dtype=float32)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_queries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "998331f5-1f67-4e09-8ffe-3b75aca0a9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from li.utils import pairwise_cosine\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "from li.BaseLMI import cluster_kmeans_faiss, cluster_kmedoids\n",
    "from li.BaseLMI import BaseLMI\n",
    "prepare_data_cluster_kmedoids = BaseLMI.prepare_data_cluster_kmedoids\n",
    "collect_predictions_kmedoids = BaseLMI.collect_predictions_kmedoids\n",
    "from li.model import NeuralNetwork, data_X_to_torch, data_to_torch\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96f1e526-3ee4-4d47-8e80-02fd914375da",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "n_categories=1000\n",
    "epochs=100\n",
    "lr=0.1\n",
    "model_type='MLP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "922becb7-7cd8-453d-81be-25f8fb2c729d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-04 19:24:41,551][INFO ][__main__] Starting training\n",
      "[2023-07-04 19:24:41,555][INFO ][__main__] Epochs: 100, step: 10\n",
      "[2023-07-04 19:25:08,326][INFO ][__main__] Epoch 10 | Loss 0.8489696979522705\n",
      "[2023-07-04 19:25:39,862][INFO ][__main__] Epoch 20 | Loss 0.347359836101532\n",
      "[2023-07-04 19:27:47,805][INFO ][__main__] Epoch 30 | Loss 0.18590112030506134\n",
      "[2023-07-04 19:31:56,197][INFO ][__main__] Epoch 40 | Loss 0.11469919979572296\n",
      "[2023-07-04 19:36:55,095][INFO ][__main__] Epoch 50 | Loss 0.0794241800904274\n",
      "[2023-07-04 19:41:57,903][INFO ][__main__] Epoch 60 | Loss 0.05990879237651825\n",
      "[2023-07-04 19:46:50,506][INFO ][__main__] Epoch 70 | Loss 0.047846656292676926\n",
      "[2023-07-04 19:51:25,096][INFO ][__main__] Epoch 80 | Loss 0.03951886296272278\n",
      "[2023-07-04 19:55:19,481][INFO ][__main__] Epoch 90 | Loss 0.033408571034669876\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(\n",
    "    input_dim=data.shape[1], output_dim=n_categories, lr=lr, model_type=model_type\n",
    ")\n",
    "data_x, data_y = data_to_torch(data_prep[:100_000], result[:100_000])\n",
    "#data_x, data_y = data_to_torch(data_part, labels)\n",
    "LOG.info(f'Starting training')\n",
    "losses = nn.train(data_x, data_y, epochs=epochs, logger=LOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2145c1e-8185-4d97-8d4c-81d9c07b16c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x, data_y = data_to_torch(data_prep[100_000:200_000], result[100_000:200_000])\n",
    "#data_x, data_y = data_to_torch(data_part, labels)\n",
    "LOG.info(f'Starting training')\n",
    "losses = nn.train(data_x, data_y, epochs=epochs, logger=LOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99975e01-8e94-4b95-a4d4-fd5cb9e71010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([      0,  100000,  200000,  300000,  400000,  500000,  600000,\n",
       "        700000,  800000,  900000, 1000000, 1100000, 1200000, 1300000,\n",
       "       1400000, 1500000, 1600000, 1700000, 1800000, 1900000, 2000000,\n",
       "       2100000, 2200000, 2300000, 2400000, 2500000, 2600000, 2700000,\n",
       "       2800000, 2900000, 3000000, 3100000, 3200000, 3300000, 3400000,\n",
       "       3500000, 3600000, 3700000, 3800000, 3900000, 4000000, 4100000,\n",
       "       4200000, 4300000, 4400000, 4500000, 4600000, 4700000, 4800000,\n",
       "       4900000, 5000000, 5100000, 5200000, 5300000, 5400000, 5500000,\n",
       "       5600000, 5700000, 5800000, 5900000, 6000000, 6100000, 6200000,\n",
       "       6300000, 6400000, 6500000, 6600000, 6700000, 6800000, 6900000,\n",
       "       7000000, 7100000, 7200000, 7300000, 7400000, 7500000, 7600000,\n",
       "       7700000, 7800000, 7900000, 8000000, 8100000, 8200000, 8300000,\n",
       "       8400000, 8500000, 8600000, 8700000, 8800000, 8900000, 9000000,\n",
       "       9100000, 9200000, 9300000, 9400000, 9500000, 9600000, 9700000,\n",
       "       9800000, 9900000])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0, 10_000_000, 100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646fd1e1-5a85-4b58-8df6-3a1ee28bfd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans().fit(preprocessing.normalize(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "92252211-2bf0-46af-b1a4-d561de10a7ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/mnt/storage-brno11-elixir/home/tslaninakova/dynamic-lmi/dynamic-lmi-env/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1314\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1316\u001b[0m                 \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage-brno11-elixir/home/tslaninakova/dynamic-lmi/dynamic-lmi-env/lib/python3.6/site-packages/sklearn/cluster/_dbscan.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    334\u001b[0m         neighborhoods = neighbors_model.radius_neighbors(X,\n\u001b[0;32m--> 335\u001b[0;31m                                                          return_distance=False)\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage-brno11-elixir/home/tslaninakova/dynamic-lmi/dynamic-lmi-env/lib/python3.6/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mradius_neighbors\u001b[0;34m(self, X, radius, return_distance, sort_results)\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m                 \u001b[0mneigh_ind_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunked_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_object_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneigh_ind_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage-brno11-elixir/home/tslaninakova/dynamic-lmi/dynamic-lmi-env/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1623\u001b[0m         D_chunk = pairwise_distances(X_chunk, Y, metric=metric,\n\u001b[0;32m-> 1624\u001b[0;31m                                      n_jobs=n_jobs, **kwds)\n\u001b[0m\u001b[1;32m   1625\u001b[0m         if ((X is Y or Y is None)\n",
      "\u001b[0;32m/mnt/storage-brno11-elixir/home/tslaninakova/dynamic-lmi/dynamic-lmi-env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage-brno11-elixir/home/tslaninakova/dynamic-lmi/dynamic-lmi-env/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage-brno11-elixir/home/tslaninakova/dynamic-lmi/dynamic-lmi-env/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage-brno11-elixir/home/tslaninakova/dynamic-lmi/dynamic-lmi-env/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_distances\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m    832\u001b[0m     \u001b[0;31m# 1.0 - cosine_similarity(X, Y) without copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m     \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage-brno11-elixir/home/tslaninakova/dynamic-lmi/dynamic-lmi-env/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m         \u001b[0mY_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage-brno11-elixir/home/tslaninakova/dynamic-lmi/dynamic-lmi-env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage-brno11-elixir/home/tslaninakova/dynamic-lmi/dynamic-lmi-env/lib/python3.6/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[1;32m   1927\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m             \u001b[0mnorms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1929\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage-brno11-elixir/home/tslaninakova/dynamic-lmi/dynamic-lmi-env/lib/python3.6/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36mrow_norms\u001b[0;34m(X, squared)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mnorms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ij,ij->i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/mnt/storage-brno11-elixir/home/tslaninakova/dynamic-lmi/dynamic-lmi-env/lib/python3.6/site-packages/numpy/core/einsumfunc.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[1;32m   1349\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mc_einsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-b40da4af1aa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"clusters = DBSCAN(\\n    eps=0.2, min_samples=4, metric='cosine', leaf_size=9, p=0.005\\n).fit(data_s.values)\\n# eps = 0.5\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/storage-brno11-elixir/home/tslaninakova/dynamic-lmi/dynamic-lmi-env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2369\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2370\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2371\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2372\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage-brno11-elixir/home/tslaninakova/dynamic-lmi/dynamic-lmi-env/lib/python3.6/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage-brno11-elixir/home/tslaninakova/dynamic-lmi/dynamic-lmi-env/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage-brno11-elixir/home/tslaninakova/dynamic-lmi/dynamic-lmi-env/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1313\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1316\u001b[0m                 \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m                 \u001b[0;31m# multi-line %%time case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clusters = DBSCAN(\n",
    "    eps=0.2, min_samples=4, metric='cosine', leaf_size=9, p=0.005\n",
    ").fit(data_s.values)\n",
    "# eps = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471945c8-9b47-4eb3-b679-1aa841c6a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_result = np.unique(clusters.labels_, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "13fb537f-1983-41ad-bb11-a2a6c836f1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n",
       "        16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]),\n",
       " array([11172, 88727,     4,     4,     1,     6,     4,     3,    11,\n",
       "            4,     1,     3,     4,     3,     4,     5,     4,     4,\n",
       "            4,     3,     3,     2,     4,     4,     2,     2,     3,\n",
       "            5,     4]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "448113f0-bec2-447f-b29b-2c56fecbacba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88727"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_result[1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9e21be93-25db-493e-a332-68c2c0e283ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a11a5c4f-ab69-4665-80ec-3e661ec39892",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = listdir('/auto/brno12-cerit/nfs4/home/tslaninakova/sisap-challenge/results-dbscan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "56a5d6e5-4417-4439-811e-d8c78e97dcad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99916"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min([int(r_.split('.csv')[0].split('-')[-1]) + int(r_.split('.csv')[0].split('-')[-2]) for r_ in r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7b7ae95c-f4be-4370-ae30-5a474d7cfce7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "56796 is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-e815bd325964>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m56796\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: 56796 is not in list"
     ]
    }
   ],
   "source": [
    "[int(r_.split('.csv')[0].split('-')[-1]) + int(r_.split('.csv')[0].split('-')[-2]) for r_ in r].index(56796)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a3fc586b-b8e2-4c38-bd17-e698b959c229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-07-04--17-12-10-28398-28398.csv'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6447f043-c9ee-4ab6-9935-b9841af4b072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "026406ef-853f-4d79-9e16-01aebe16aa2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11172"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_result[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5a932a82-61fa-41ef-b00e-59ab7644dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_s = data.loc[100_000:200_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a6d2c524-494e-45d1-a645-585ffc6bf725",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters2 = DBSCAN(\n",
    "    eps=0.2, min_samples=4, metric='cosine', leaf_size=9, p=0.005\n",
    ").fit(data_s.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a2403c0f-550f-4d4b-974f-1b2c5b6ad722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11346"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_result2 = np.unique(clusters2.labels_, return_counts=True)\n",
    "unique_result2[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cb7bc1a5-6eec-4526-a56d-e914f7f35aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72320, 32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1 = data.loc[:100_000]\n",
    "data_1 = data_1.loc[clusters.labels_ == -1]\n",
    "data_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b188ffc7-897f-4330-ad79-b3034fb5d5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a680f38c-23ce-4cf7-8acc-c9e6bb9a9477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71964, 32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2 = data.loc[100_000:200_000]\n",
    "data_2 = data_2.loc[clusters2.labels_ == -1]\n",
    "data_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3b4cadc7-8183-43ff-b6de-c3e0433c0636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.142266</td>\n",
       "      <td>0.121459</td>\n",
       "      <td>-0.054467</td>\n",
       "      <td>-0.058987</td>\n",
       "      <td>0.049365</td>\n",
       "      <td>-0.107044</td>\n",
       "      <td>0.123232</td>\n",
       "      <td>0.003732</td>\n",
       "      <td>0.044797</td>\n",
       "      <td>-0.118452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063983</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>-0.089511</td>\n",
       "      <td>0.077113</td>\n",
       "      <td>-0.118540</td>\n",
       "      <td>0.058264</td>\n",
       "      <td>0.065489</td>\n",
       "      <td>0.028578</td>\n",
       "      <td>-0.089683</td>\n",
       "      <td>0.126804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.213747</td>\n",
       "      <td>-0.011409</td>\n",
       "      <td>-0.015184</td>\n",
       "      <td>0.149988</td>\n",
       "      <td>0.106374</td>\n",
       "      <td>0.082410</td>\n",
       "      <td>-0.120636</td>\n",
       "      <td>-0.061065</td>\n",
       "      <td>0.068683</td>\n",
       "      <td>0.033811</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098325</td>\n",
       "      <td>-0.013612</td>\n",
       "      <td>0.004494</td>\n",
       "      <td>-0.046666</td>\n",
       "      <td>-0.043621</td>\n",
       "      <td>-0.086326</td>\n",
       "      <td>-0.011769</td>\n",
       "      <td>-0.047742</td>\n",
       "      <td>0.020944</td>\n",
       "      <td>-0.030367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.069696</td>\n",
       "      <td>-0.213891</td>\n",
       "      <td>0.132873</td>\n",
       "      <td>-0.150283</td>\n",
       "      <td>-0.049209</td>\n",
       "      <td>0.080035</td>\n",
       "      <td>-0.023633</td>\n",
       "      <td>0.017212</td>\n",
       "      <td>-0.208762</td>\n",
       "      <td>0.053342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035556</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>-0.048412</td>\n",
       "      <td>-0.051262</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>-0.036998</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.011270</td>\n",
       "      <td>-0.029592</td>\n",
       "      <td>0.076340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.136413</td>\n",
       "      <td>-0.124811</td>\n",
       "      <td>-0.154160</td>\n",
       "      <td>0.239878</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>0.145432</td>\n",
       "      <td>-0.069391</td>\n",
       "      <td>-0.006645</td>\n",
       "      <td>0.124315</td>\n",
       "      <td>0.054875</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045162</td>\n",
       "      <td>0.027401</td>\n",
       "      <td>0.072960</td>\n",
       "      <td>-0.035548</td>\n",
       "      <td>-0.003664</td>\n",
       "      <td>-0.007761</td>\n",
       "      <td>-0.065726</td>\n",
       "      <td>-0.013585</td>\n",
       "      <td>-0.012794</td>\n",
       "      <td>-0.030778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.389241</td>\n",
       "      <td>0.076076</td>\n",
       "      <td>-0.072001</td>\n",
       "      <td>0.103547</td>\n",
       "      <td>-0.058551</td>\n",
       "      <td>0.033468</td>\n",
       "      <td>0.017906</td>\n",
       "      <td>0.094761</td>\n",
       "      <td>0.034065</td>\n",
       "      <td>-0.220189</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051880</td>\n",
       "      <td>-0.016713</td>\n",
       "      <td>0.018730</td>\n",
       "      <td>0.050222</td>\n",
       "      <td>-0.021090</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>0.043465</td>\n",
       "      <td>-0.049461</td>\n",
       "      <td>-0.052292</td>\n",
       "      <td>0.027773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>-0.016623</td>\n",
       "      <td>0.261374</td>\n",
       "      <td>-0.108525</td>\n",
       "      <td>-0.135211</td>\n",
       "      <td>0.032195</td>\n",
       "      <td>0.070787</td>\n",
       "      <td>0.079449</td>\n",
       "      <td>-0.092412</td>\n",
       "      <td>-0.100304</td>\n",
       "      <td>0.067358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081138</td>\n",
       "      <td>-0.013030</td>\n",
       "      <td>0.065910</td>\n",
       "      <td>-0.052886</td>\n",
       "      <td>0.022053</td>\n",
       "      <td>0.036298</td>\n",
       "      <td>-0.059659</td>\n",
       "      <td>0.027475</td>\n",
       "      <td>-0.006544</td>\n",
       "      <td>-0.060666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>-0.135043</td>\n",
       "      <td>0.058869</td>\n",
       "      <td>-0.033821</td>\n",
       "      <td>-0.066608</td>\n",
       "      <td>-0.032245</td>\n",
       "      <td>0.102940</td>\n",
       "      <td>0.085796</td>\n",
       "      <td>0.028704</td>\n",
       "      <td>0.096673</td>\n",
       "      <td>-0.053070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040772</td>\n",
       "      <td>-0.024435</td>\n",
       "      <td>0.013444</td>\n",
       "      <td>0.064723</td>\n",
       "      <td>0.059284</td>\n",
       "      <td>-0.020601</td>\n",
       "      <td>0.065155</td>\n",
       "      <td>-0.004740</td>\n",
       "      <td>-0.011218</td>\n",
       "      <td>-0.096802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>0.056166</td>\n",
       "      <td>0.045453</td>\n",
       "      <td>-0.165639</td>\n",
       "      <td>-0.001400</td>\n",
       "      <td>0.177127</td>\n",
       "      <td>-0.021528</td>\n",
       "      <td>-0.009026</td>\n",
       "      <td>-0.040884</td>\n",
       "      <td>0.220318</td>\n",
       "      <td>-0.039731</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096172</td>\n",
       "      <td>0.015361</td>\n",
       "      <td>-0.034067</td>\n",
       "      <td>-0.060641</td>\n",
       "      <td>0.030858</td>\n",
       "      <td>0.005659</td>\n",
       "      <td>0.010588</td>\n",
       "      <td>0.035196</td>\n",
       "      <td>-0.021983</td>\n",
       "      <td>0.015925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>0.172810</td>\n",
       "      <td>0.136016</td>\n",
       "      <td>0.052640</td>\n",
       "      <td>-0.048010</td>\n",
       "      <td>0.118766</td>\n",
       "      <td>-0.002332</td>\n",
       "      <td>0.111289</td>\n",
       "      <td>-0.026583</td>\n",
       "      <td>-0.051066</td>\n",
       "      <td>-0.125786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088246</td>\n",
       "      <td>-0.000755</td>\n",
       "      <td>0.012355</td>\n",
       "      <td>0.057855</td>\n",
       "      <td>-0.032556</td>\n",
       "      <td>0.118518</td>\n",
       "      <td>-0.025377</td>\n",
       "      <td>0.024111</td>\n",
       "      <td>0.063948</td>\n",
       "      <td>-0.016831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>0.063618</td>\n",
       "      <td>0.235884</td>\n",
       "      <td>-0.208040</td>\n",
       "      <td>-0.134384</td>\n",
       "      <td>0.053721</td>\n",
       "      <td>0.047269</td>\n",
       "      <td>-0.019174</td>\n",
       "      <td>-0.021357</td>\n",
       "      <td>0.054352</td>\n",
       "      <td>0.105734</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019659</td>\n",
       "      <td>0.017532</td>\n",
       "      <td>-0.063930</td>\n",
       "      <td>-0.017096</td>\n",
       "      <td>0.025376</td>\n",
       "      <td>0.015632</td>\n",
       "      <td>-0.120720</td>\n",
       "      <td>-0.062884</td>\n",
       "      <td>-0.070018</td>\n",
       "      <td>-0.083679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144284 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6   \\\n",
       "1       0.142266  0.121459 -0.054467 -0.058987  0.049365 -0.107044  0.123232   \n",
       "2       0.213747 -0.011409 -0.015184  0.149988  0.106374  0.082410 -0.120636   \n",
       "3       0.069696 -0.213891  0.132873 -0.150283 -0.049209  0.080035 -0.023633   \n",
       "4       0.136413 -0.124811 -0.154160  0.239878  0.002287  0.145432 -0.069391   \n",
       "5      -0.389241  0.076076 -0.072001  0.103547 -0.058551  0.033468  0.017906   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "199995 -0.016623  0.261374 -0.108525 -0.135211  0.032195  0.070787  0.079449   \n",
       "199996 -0.135043  0.058869 -0.033821 -0.066608 -0.032245  0.102940  0.085796   \n",
       "199997  0.056166  0.045453 -0.165639 -0.001400  0.177127 -0.021528 -0.009026   \n",
       "199998  0.172810  0.136016  0.052640 -0.048010  0.118766 -0.002332  0.111289   \n",
       "199999  0.063618  0.235884 -0.208040 -0.134384  0.053721  0.047269 -0.019174   \n",
       "\n",
       "              7         8         9   ...        22        23        24  \\\n",
       "1       0.003732  0.044797 -0.118452  ...  0.063983  0.037666 -0.089511   \n",
       "2      -0.061065  0.068683  0.033811  ... -0.098325 -0.013612  0.004494   \n",
       "3       0.017212 -0.208762  0.053342  ...  0.035556  0.023209 -0.048412   \n",
       "4      -0.006645  0.124315  0.054875  ... -0.045162  0.027401  0.072960   \n",
       "5       0.094761  0.034065 -0.220189  ... -0.051880 -0.016713  0.018730   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "199995 -0.092412 -0.100304  0.067358  ...  0.081138 -0.013030  0.065910   \n",
       "199996  0.028704  0.096673 -0.053070  ... -0.040772 -0.024435  0.013444   \n",
       "199997 -0.040884  0.220318 -0.039731  ... -0.096172  0.015361 -0.034067   \n",
       "199998 -0.026583 -0.051066 -0.125786  ...  0.088246 -0.000755  0.012355   \n",
       "199999 -0.021357  0.054352  0.105734  ... -0.019659  0.017532 -0.063930   \n",
       "\n",
       "              25        26        27        28        29        30        31  \n",
       "1       0.077113 -0.118540  0.058264  0.065489  0.028578 -0.089683  0.126804  \n",
       "2      -0.046666 -0.043621 -0.086326 -0.011769 -0.047742  0.020944 -0.030367  \n",
       "3      -0.051262  0.019094 -0.036998  0.006380  0.011270 -0.029592  0.076340  \n",
       "4      -0.035548 -0.003664 -0.007761 -0.065726 -0.013585 -0.012794 -0.030778  \n",
       "5       0.050222 -0.021090  0.004709  0.043465 -0.049461 -0.052292  0.027773  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "199995 -0.052886  0.022053  0.036298 -0.059659  0.027475 -0.006544 -0.060666  \n",
       "199996  0.064723  0.059284 -0.020601  0.065155 -0.004740 -0.011218 -0.096802  \n",
       "199997 -0.060641  0.030858  0.005659  0.010588  0.035196 -0.021983  0.015925  \n",
       "199998  0.057855 -0.032556  0.118518 -0.025377  0.024111  0.063948 -0.016831  \n",
       "199999 -0.017096  0.025376  0.015632 -0.120720 -0.062884 -0.070018 -0.083679  \n",
       "\n",
       "[144284 rows x 32 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([data_1, data_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3f7a4d95-b1c7-45bf-a259-dc3c641c103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters3 = DBSCAN(\n",
    "    eps=0.1, min_samples=5, metric='cosine', leaf_size=10, p=0.01\n",
    ").fit(pd.concat([data_1, data_2]).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6f4849b5-3521-4daa-aa79-5ffca9feb497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140027"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_result3 = np.unique(clusters3.labels_, return_counts=True)\n",
    "unique_result3[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d370fe7c-bb1c-4085-bd53-190dd4d3a0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2df5deef-ba06-48f4-9be4-fb192f649bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72315, 32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_s.loc[clusters.labels_ == -1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1dc557-1807-4a16-9533-5ff351839ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "100c2d6d-5857-4456-bf07-1b95249b632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_2 = DBSCAN(\n",
    "    eps=0.1, min_samples=5, metric='cosine', leaf_size=10, p=0.01\n",
    ").fit(data_s.loc[clusters.labels_ == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a798c234-25dc-4b66-95ff-f256757dc1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_result_2 = np.unique(clusters_2.labels_, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "da8f50a1-3047-41a1-9b14-8eea1d505026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72315"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_result_2[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5233011-19a6-46ed-bc36-45eab10feeec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a80d59ca-0359-428d-8ef3-179a77fa446c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78487"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_result[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb889f5-60ab-485c-aa1f-5143b5b2cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time clusters = DBSCAN(eps=3, min_samples=2).fit(data_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1adb5224-0453-47db-9b6f-892392c4142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ff843d-2ce9-4f15-bd90-c9b27662d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_clip_data[:1_000_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "97e1a0bf-db7c-42d5-a98e-31360e0cc15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_queries[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f179ac1-6a5a-42a3-85e6-96eb4d77da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_queries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "857e169e-17b5-4386-88c5-0c55eb9e4326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4304a49c-91b2-4f55-9dd4-6455c8d8ede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_part_sparse = sparse.csr_matrix(clip_data.loc[object_ids])\n",
    "query_part_sparse = sparse.csr_matrix(loaded_queries_seq[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc073bd-efdb-4fac-9b80-6f96ca5d8531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d83326b9-64ca-4137-9890-5a660d614136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.19 s, sys: 2.2 s, total: 6.39 s\n",
      "Wall time: 6.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = cdist(\n",
    "    [loaded_queries_seq[0]], loaded_clip_data[:1_000_000], metric='cosine'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6c9197f5-816b-4250-b610-5cfe6a18d8a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "XA must be a 2-dimensional array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage-brno11-elixir/home/tslaninakova/dynamic-lmi/dynamic-lmi-env/lib/python3.6/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mcdist\u001b[0;34m(XA, XB, metric, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2708\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'XA must be a 2-dimensional array.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2709\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msB\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2710\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'XB must be a 2-dimensional array.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: XA must be a 2-dimensional array."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = cdist(\n",
    "    sparse.csr_matrix(loaded_queries_seq[:2]), sparse.csr_matrix(loaded_clip_data[:1_000_000]), metric='cosine'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8065f40c-cb5d-4131-aa57-517a109d6f15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
