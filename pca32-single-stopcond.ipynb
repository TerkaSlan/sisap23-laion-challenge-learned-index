{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c98346b6-24df-4315-987c-6079be4dbbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75496986-547a-4da3-9872-60c4d562be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from li.utils import pairwise_cosine\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import sparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "474bc223-4a15-476b-a5ea-78bf37affba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='[%(asctime)s][%(levelname)-5.5s][%(name)-.20s] %(message)s'\n",
    ")\n",
    "LOG = logging.getLogger(__name__)\n",
    "\n",
    "def increase_max_recursion_limit():\n",
    "    \"\"\" Increases the maximum recursion limit.\n",
    "    Source: https://stackoverflow.com/a/16248113\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    import resource\n",
    "    resource.setrlimit(resource.RLIMIT_STACK, (2**29, -1))\n",
    "    sys.setrecursionlimit(10**6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6658bfd0-b3f8-4736-b148-2e78a1efe016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-06 14:38:03,909][INFO ][__main__] Loading pca32 data\n",
      "[2023-07-06 14:38:17,250][INFO ][__main__] Loading queries\n",
      "[2023-07-06 14:38:17,706][INFO ][__main__] Loading clip data\n",
      "[2023-07-06 14:40:57,614][INFO ][__main__] Loading GT\n"
     ]
    }
   ],
   "source": [
    "size = '10M'\n",
    "\n",
    "LOG.info(f'Loading pca32 data')\n",
    "data_path = f'data/pca32v2/{size}/dataset.h5'\n",
    "f = h5py.File(data_path, 'r')\n",
    "loaded_data = f['pca32'][:, :]\n",
    "data = pd.DataFrame(loaded_data)\n",
    "data.index += 1\n",
    "\n",
    "LOG.info(f'Loading queries')\n",
    "base_path = f'data/pca32v2/{size}/'\n",
    "queries_path = f'{base_path}/query.h5'\n",
    "f2 = h5py.File(queries_path, 'r')\n",
    "#loaded_queries = f2['emb'][:, :]\n",
    "loaded_queries = f2['pca32'][:, :]\n",
    "\n",
    "base_path = f'data/clip768v2/{size}/'\n",
    "queries_path = f'{base_path}/query.h5'\n",
    "f2 = h5py.File(queries_path, 'r')\n",
    "#loaded_queries = f2['emb'][:, :]\n",
    "loaded_queries_seq = f2['emb'][:, :]\n",
    "\n",
    "LOG.info(f'Loading clip data')\n",
    "data_path = f'data/clip768v2/{size}/dataset.h5'\n",
    "f = h5py.File(data_path, 'r')\n",
    "loaded_clip_data = f['emb'][:, :]\n",
    "loaded_clip_data = pd.DataFrame(loaded_clip_data)\n",
    "loaded_clip_data.index += 1\n",
    "\n",
    "LOG.info(f'Loading GT')\n",
    "gt_path = f'data/groundtruth-{size}.h5'\n",
    "f3 = h5py.File(gt_path, 'r')\n",
    "loaded_gt = f3['knns'][:, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b2ebf478-b882-4d03-9515-056d917cc4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from li.BaseLMI import cluster_kmeans_faiss\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d72a2370-2418-49ae-92f0-92175be8cfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.15 s, sys: 313 ms, total: 5.47 s\n",
      "Wall time: 5.58 s\n"
     ]
    }
   ],
   "source": [
    "%time kmeans, result = cluster_kmeans_faiss(data, n_clusters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a147a9b6-658c-4261-a778-faf6e1b9777a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "        51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "        68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "        85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
       " array([137846,  84578,  64977,  63083, 121910,  66487, 112356, 143534,\n",
       "        107602, 127883, 119215, 126814,  82047,  82712,  53245,  69419,\n",
       "        133778, 121060, 139095,  83346,  58019,  46916, 119296,  60359,\n",
       "         91497,  41448,  94526, 147443,  63823, 114869, 123470, 102668,\n",
       "         92954,  55334, 103322, 179235,  83676,  94945,  69837, 163405,\n",
       "        109906, 128452,  67458,  90685,  70172,  60274,  98134, 128141,\n",
       "        111783, 134609, 113524,  70085,  85169,  84793,  92790,  90704,\n",
       "        138608, 146013,  74300, 100450, 145770, 164127,  68269,  71311,\n",
       "         88797, 121934, 152438,  91117,  58709,  95351, 126839,  63625,\n",
       "        147519,  64592,  63377, 140213,  98430,  52382,  84354, 129583,\n",
       "         98848, 107406,  91506,  83728, 140164,  48424,  78287,  96613,\n",
       "        155015,  70988, 123089,  84975, 163195,  65014,  88034, 102433,\n",
       "        166184, 129430, 131956, 122086]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(result, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f0c6a3c1-8d62-4ce0-97e2-80e12555796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "from li.model import NeuralNetwork, data_X_to_torch, data_to_torch, LIDataset_Single\n",
    "        \n",
    "dataset = LIDataset_Single(data, result)\n",
    "        \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=256,\n",
    "    sampler=torch.utils.data.SubsetRandomSampler(data.index.values.tolist())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6af13d9a-9a94-4e74-8c63-e967f664a90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(\n",
    "    input_dim=data.shape[1], output_dim=100, lr=0.1, model_type='MLP'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceae4bd-d7e5-410a-881f-fd9495361e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-06 14:41:09,487][INFO ][__main__] Epochs: 100, step: 10\n",
      "[2023-07-06 15:04:47,288][INFO ][__main__] Epoch 10 | Loss 1.78789\n"
     ]
    }
   ],
   "source": [
    "%time losses = nn.train_batch(train_loader, epochs=100, logger=LOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44654a15-6005-426e-b4e9-203a4a63009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time data['category_nn'] = nn.predict(data_X_to_torch(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492c98a7-c693-4506-b60e-7cb62d0a859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['category_nn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecf636a-edfb-4a29-b132-981f92fdfb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time probs, classes = nn.predict_proba(data_X_to_torch(loaded_queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abedbd91-1803-451e-b40d-959f2dbb650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "k=10\n",
    "nns = np.zeros((loaded_queries.shape[0], k), dtype=np.uint32)\n",
    "dists = np.zeros((loaded_queries.shape[0], k), dtype=np.float32)\n",
    "for class_ in np.unique(classes[:, 0]):\n",
    "    cat_idxs = np.where(classes[:, 0] == class_)[0]\n",
    "    bucket_obj_indexes = data.query(f'category_nn == {class_}', engine='python').index\n",
    "    seq_search_dists = pairwise_cosine(loaded_queries_seq[cat_idxs], loaded_clip_data.loc[bucket_obj_indexes])\n",
    "    ann_relative = seq_search_dists.argsort()[:, :k]\n",
    "    nns[cat_idxs] = np.array(bucket_obj_indexes)[ann_relative]\n",
    "    dists[cat_idxs] = np.take_along_axis(seq_search_dists, ann_relative, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3be3ff-b570-47ad-b9f8-edae939e9fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3becea22-a61e-4db4-bd4f-ebb1b11b2914",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps = []\n",
    "for i in range(10_000):\n",
    "    overlaps.append(np.intersect1d(nns[i], loaded_gt[i]).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb657ffe-f426-4a76-88f8-96f39f2d9c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b347a0ae-ab31-475c-85cf-58c5d9d17765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
