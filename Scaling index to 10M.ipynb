{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2cdb38d-1cd3-4dcc-8a60-2ec8e6f05ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eea08abe-1263-427e-a3b7-b42adf1d5599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.3 ms, sys: 1.14 s, total: 1.15 s\n",
      "Wall time: 1.25 s\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "data_path = 'data/clip768v2/10M/dataset.h5'\n",
    "%time f = h5py.File(data_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "170d527d-dd1b-4716-9454-0829de3292cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10120191"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f['emb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313af20e-7ac3-4002-afc9-9b72773b5652",
   "metadata": {},
   "source": [
    "## Goal:\n",
    "1) load data for training (1000*1000 objects)\n",
    "2) train, predict on train, dispose of the training data (keep ids)\n",
    "3) load data for predict (rest 9M objects)\n",
    "4) predict, dispose of the data (keep ids)\n",
    "5) on search, load the data in the visited bucket again (10k objects on avg), compute distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea207e6d-2cea-4ebe-8c3a-947bbae07b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.randint(2, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9d370de-5925-4326-9743-03dc399e2df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.1 ms, sys: 10.5 s, total: 10.5 s\n",
      "Wall time: 2min 40s\n"
     ]
    }
   ],
   "source": [
    "%time loaded_data = f['emb'][:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8effd8a-9ce8-4b3b-b325-5c2d565ecda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 291 µs, sys: 105 ms, total: 105 ms\n",
      "Wall time: 182 ms\n",
      "CPU times: user 15.3 ms, sys: 815 ms, total: 831 ms\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "data_path_32 = 'data/pca32v2/10M/dataset.h5'\n",
    "%time f = h5py.File(data_path_32, 'r')\n",
    "%time loaded_data_pca = f['pca32'][:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06fb66c8-ef44-4dcf-9b01-27e0d6eb3306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from li.BulkLMI import BulkLMI\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c09397e0-68f3-40d8-abd5-6eba339abcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(loaded_data)\n",
    "data.index += 1\n",
    "data_s = data.sample(1_000_000, random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aff14d57-ddcb-465d-b3ec-43887bac6df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 604 ms, sys: 27.9 ms, total: 632 ms\n",
      "Wall time: 644 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "blmi = BulkLMI()\n",
    "blmi.insert(data_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b63f7652-5362-4be7-a42b-a5335c2438f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='[%(asctime)s][%(levelname)-5.5s][%(name)-.20s] %(message)s'\n",
    ")\n",
    "LOG = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d6e5b1e5-ae5e-40f7-87cb-7d233aaaad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = LogisticRegression(random_state=0).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a74cd039-5622-45bf-a9d7-bc4184f71bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-01 11:36:17,540][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.1 s, sys: 1.57 s, total: 38.6 s\n",
      "Wall time: 39.6 s\n"
     ]
    }
   ],
   "source": [
    "info_df = pd.DataFrame([], columns=['op', 'time-taken', 'size', '#-objects'])\n",
    "%time info_df = blmi.deepen(blmi.nodes[(0, )], 100, info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0dda9079-07db-4fdb-a6ae-e401fd981c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-01 11:36:57,253][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError: weight tensor should be defined either for all 100 classes or no classes but got weight tensor of shape: [5] at /pytorch/aten/src/THNN/generic/ClassNLLCriterion.c:28 -- caught, training without class weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-01 11:36:57,470][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 1)\n",
      "[2023-07-01 11:36:59,742][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 2)\n",
      "[2023-07-01 11:37:02,406][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 3)\n",
      "[2023-07-01 11:37:04,659][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 4)\n",
      "[2023-07-01 11:37:06,847][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 5)\n",
      "[2023-07-01 11:37:09,176][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 6)\n",
      "[2023-07-01 11:37:11,345][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 7)\n",
      "[2023-07-01 11:37:13,803][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 8)\n",
      "[2023-07-01 11:37:15,976][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 9)\n",
      "[2023-07-01 11:37:18,231][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 10)\n",
      "[2023-07-01 11:37:20,345][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 11)\n",
      "[2023-07-01 11:37:22,600][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 12)\n",
      "[2023-07-01 11:37:24,888][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 13)\n",
      "[2023-07-01 11:37:27,248][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 14)\n",
      "[2023-07-01 11:37:29,687][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 15)\n",
      "[2023-07-01 11:37:32,002][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError: weight tensor should be defined either for all 100 classes or no classes but got weight tensor of shape: [16] at /pytorch/aten/src/THNN/generic/ClassNLLCriterion.c:28 -- caught, training without class weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-01 11:37:32,437][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 17)\n",
      "[2023-07-01 11:37:35,005][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 18)\n",
      "[2023-07-01 11:37:37,332][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 19)\n",
      "[2023-07-01 11:37:40,001][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 20)\n",
      "[2023-07-01 11:37:42,461][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 21)\n",
      "[2023-07-01 11:37:44,852][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 22)\n",
      "[2023-07-01 11:37:47,171][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 23)\n",
      "[2023-07-01 11:37:49,820][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 24)\n",
      "[2023-07-01 11:37:52,025][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 25)\n",
      "[2023-07-01 11:37:54,302][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 26)\n",
      "[2023-07-01 11:37:56,658][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 27)\n",
      "[2023-07-01 11:37:59,058][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 28)\n",
      "[2023-07-01 11:38:01,285][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 29)\n",
      "[2023-07-01 11:38:04,233][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 30)\n",
      "[2023-07-01 11:38:06,580][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 31)\n",
      "[2023-07-01 11:38:08,951][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 32)\n",
      "[2023-07-01 11:38:11,526][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 33)\n",
      "[2023-07-01 11:38:14,034][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 34)\n",
      "[2023-07-01 11:38:16,757][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 35)\n",
      "[2023-07-01 11:38:19,429][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 36)\n",
      "[2023-07-01 11:38:21,898][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 37)\n",
      "[2023-07-01 11:38:24,181][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 38)\n",
      "[2023-07-01 11:38:27,054][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 39)\n",
      "[2023-07-01 11:38:29,557][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 40)\n",
      "[2023-07-01 11:38:32,251][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 41)\n",
      "[2023-07-01 11:38:34,733][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 42)\n",
      "[2023-07-01 11:38:37,256][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 43)\n",
      "[2023-07-01 11:38:39,967][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 44)\n",
      "[2023-07-01 11:38:42,481][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 45)\n",
      "[2023-07-01 11:38:45,144][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 46)\n",
      "[2023-07-01 11:38:47,784][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 47)\n",
      "[2023-07-01 11:38:50,340][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 48)\n",
      "[2023-07-01 11:38:53,241][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 49)\n",
      "[2023-07-01 11:38:55,733][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 50)\n",
      "[2023-07-01 11:38:58,353][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 51)\n",
      "[2023-07-01 11:39:01,030][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 52)\n",
      "[2023-07-01 11:39:03,772][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 53)\n",
      "[2023-07-01 11:39:06,406][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 54)\n",
      "[2023-07-01 11:39:09,007][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 55)\n",
      "[2023-07-01 11:39:11,786][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 56)\n",
      "[2023-07-01 11:39:14,318][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 57)\n",
      "[2023-07-01 11:39:16,949][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 58)\n",
      "[2023-07-01 11:39:19,743][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 59)\n",
      "[2023-07-01 11:39:22,212][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 60)\n",
      "[2023-07-01 11:39:24,759][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 61)\n",
      "[2023-07-01 11:39:27,506][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 62)\n",
      "[2023-07-01 11:39:30,145][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 63)\n",
      "[2023-07-01 11:39:32,740][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 64)\n",
      "[2023-07-01 11:39:35,787][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 65)\n",
      "[2023-07-01 11:39:38,534][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 67)\n",
      "[2023-07-01 11:39:41,165][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 68)\n",
      "[2023-07-01 11:39:43,973][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 69)\n",
      "[2023-07-01 11:39:46,838][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 70)\n",
      "[2023-07-01 11:39:49,826][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 71)\n",
      "[2023-07-01 11:39:52,486][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 72)\n",
      "[2023-07-01 11:39:55,089][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 73)\n",
      "[2023-07-01 11:39:57,798][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 74)\n",
      "[2023-07-01 11:40:00,407][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 75)\n",
      "[2023-07-01 11:40:03,072][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 76)\n",
      "[2023-07-01 11:40:05,999][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 77)\n",
      "[2023-07-01 11:40:08,740][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 78)\n",
      "[2023-07-01 11:40:11,582][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 79)\n",
      "[2023-07-01 11:40:14,274][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 80)\n",
      "[2023-07-01 11:40:17,322][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 81)\n",
      "[2023-07-01 11:40:20,164][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 82)\n",
      "[2023-07-01 11:40:23,236][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 83)\n",
      "[2023-07-01 11:40:25,969][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 84)\n",
      "[2023-07-01 11:40:29,174][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 85)\n",
      "[2023-07-01 11:40:32,206][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 86)\n",
      "[2023-07-01 11:40:35,111][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 87)\n",
      "[2023-07-01 11:40:37,949][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 88)\n",
      "[2023-07-01 11:40:40,519][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 89)\n",
      "[2023-07-01 11:40:43,429][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 90)\n",
      "[2023-07-01 11:40:46,308][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 91)\n",
      "[2023-07-01 11:40:49,152][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 92)\n",
      "[2023-07-01 11:40:51,811][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 93)\n",
      "[2023-07-01 11:40:54,724][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 94)\n",
      "[2023-07-01 11:40:57,923][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 95)\n",
      "[2023-07-01 11:41:00,676][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 96)\n",
      "[2023-07-01 11:41:03,878][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 97)\n",
      "[2023-07-01 11:41:07,014][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 98)\n",
      "[2023-07-01 11:41:10,126][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 99)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 7s, sys: 1.71 s, total: 4min 8s\n",
      "Wall time: 4min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, leaf in enumerate(blmi.get_leaf_nodes_pos()):\n",
    "    info_df = blmi.deepen(\n",
    "        blmi.nodes[leaf],\n",
    "        100,\n",
    "        info_df\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c312b851-107f-4236-b25f-0b567d7ddb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from li.BaseLMI import cluster_kmeans_faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d7d88cc-d364-4e17-bbae-d51e00cd7307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blmi.nodes[(0, 66)].objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "76a80c91-65c3-4a1c-be6a-48c9c7598246",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, labels = cluster_kmeans_faiss(pd.DataFrame(blmi.nodes[(0, 66)].objects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "361848d8-d3d3-4dda-9ea7-3275a7ada50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a053feac-f989-4484-a3a6-6edf92325b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 768)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bac36e4-f8a9-4994-af69-6df0d5c11a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.], dtype=float16)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros_like(data.sample(2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "01dca161-1ac2-435d-aa19-f8acc28b9604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>children</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0,)</th>\n",
       "      <td>InnerNode</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 66)</th>\n",
       "      <td>LeafNode</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 0)</th>\n",
       "      <td>InnerNode</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 0, 0)</th>\n",
       "      <td>LeafNode</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 0, 1)</th>\n",
       "      <td>LeafNode</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 99, 95)</th>\n",
       "      <td>LeafNode</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 99, 96)</th>\n",
       "      <td>LeafNode</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 99, 97)</th>\n",
       "      <td>LeafNode</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 99, 98)</th>\n",
       "      <td>LeafNode</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 99, 99)</th>\n",
       "      <td>LeafNode</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10001 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  type children\n",
       "key                            \n",
       "(0,)         InnerNode      100\n",
       "(0, 66)       LeafNode        1\n",
       "(0, 0)       InnerNode      100\n",
       "(0, 0, 0)     LeafNode        3\n",
       "(0, 0, 1)     LeafNode        1\n",
       "...                ...      ...\n",
       "(0, 99, 95)   LeafNode      243\n",
       "(0, 99, 96)   LeafNode       81\n",
       "(0, 99, 97)   LeafNode       16\n",
       "(0, 99, 98)   LeafNode       39\n",
       "(0, 99, 99)   LeafNode        9\n",
       "\n",
       "[10001 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blmi.dump_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b6144796-d80a-4784-a0ab-6c8a37beb3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9120191, 768)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_insert = data.loc[np.setdiff1d(data.index, data_s.index)]\n",
    "#blmi.insert(data_to_insert)\n",
    "data_to_insert.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "94541aba-cb73-4957-9196-a449fd9a3a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 45s, sys: 17.5 s, total: 4min 3s\n",
      "Wall time: 4min 9s\n"
     ]
    }
   ],
   "source": [
    "%time blmi.insert(data_to_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0abf394e-ef1e-4fcc-ad2a-f0b4100a0299",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'data/clip768v2/10M/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "67f801b8-b06d-4792-be91-7aa46bd8ed74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 21.9 ms, total: 21.9 ms\n",
      "Wall time: 387 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "queries_path = f'{base_path}/query.h5'\n",
    "f2 = h5py.File(queries_path, 'r')\n",
    "loaded_queries = f2['emb'][:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b2895d5a-b7c6-4102-b128-daf4a963e7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 7.49 ms, total: 7.49 ms\n",
      "Wall time: 167 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gt_path = f'data/groundtruth-10M.h5'\n",
    "f3 = h5py.File(gt_path, 'r')\n",
    "loaded_gt = f3['knns'][:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1f3d2c1f-eed1-48fc-b47b-1b35c75ba3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from li.utils import pairwise_cosine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e6b8597a-b253-4c6e-8ce9-23516a4d3e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_max_recursion_limit():\n",
    "    \"\"\" Increases the maximum recursion limit.\n",
    "    Source: https://stackoverflow.com/a/16248113\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    import resource\n",
    "    resource.setrlimit(resource.RLIMIT_STACK, (2**29, -1))\n",
    "    sys.setrecursionlimit(10**6)\n",
    "increase_max_recursion_limit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b93171d6-a9b6-40e0-886c-4fe7ac3b2f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.1 s, sys: 2min 47s, total: 3min 40s\n",
      "Wall time: 3min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res_all = []\n",
    "for i, query in tqdm(enumerate(loaded_queries)):\n",
    "    pred_leaf_nodes = blmi.search(query, stop_condition=10_000_000)[0]\n",
    "    object_ids = []\n",
    "    for pred_leaf_node in pred_leaf_nodes:\n",
    "        leaf_node = blmi.nodes.get(pred_leaf_node)\n",
    "        if leaf_node is not None:\n",
    "            object_ids.extend(leaf_node.object_ids)\n",
    "\n",
    "    #bucket_ids = [[i, mapping[bucket]] for bucket in blmi.search(query, stop_condition=500)[0]]\n",
    "    dists = pairwise_cosine([query], data.loc[object_ids])\n",
    "    break\n",
    "    res_all.extend(bucket_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fe10f21b-b41b-4ff7-affb-e55b72ac51bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = pairwise_cosine([query], data.loc[object_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7e50d82b-a06e-4a87-bb9e-4bb23aa30a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "76355c4c-79ff-443f-997f-bbf306ec568d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1831320, 7535354, 7059014, 7563483, 3003515, 5278218, 8190596,\n",
       "            9060635, 5509896,  210839],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[object_ids].index[np.argsort(dists)[:, :k][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "42bbbf99-da0a-4982-83e7-40b281ef9337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1831320, 7535354, 7059014, 7563483, 3003515, 5278218, 8190596,\n",
       "       9060635, 5509896,  210839], dtype=int32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_gt[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9d403d76-0399-4437-a0c7-bcabd4af5edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.intersect1d(\n",
    "    loaded_gt[0][:10],\n",
    "    np.array(data.loc[object_ids].index[np.argsort(dists)[:, :k][0]])[:10]\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111e8bf-4164-443c-86fb-04accf15e23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "349053c1-d67b-4aec-8582-01ac2d90ed45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.23 ms, sys: 14.3 ms, total: 17.5 ms\n",
      "Wall time: 372 ms\n"
     ]
    }
   ],
   "source": [
    "%time loaded_data = f['emb'][:10_000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08192e49-5914-46f6-b3e3-c9e409240d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.22 s, sys: 284 ms, total: 1.51 s\n",
      "Wall time: 1.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "rng = np.random.default_rng(2023)\n",
    "random_idxs = rng.choice(range(10_000_000), size=(10_000), replace=False)\n",
    "random_idxs = np.sort(random_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "073aa7c4-9dba-494e-b7bb-cc623250c17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.17 s, sys: 784 ms, total: 2.95 s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%time loaded_data = f['emb'][random_idxs, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bc10f6c-3ecc-4666-b4d3-a262969b254b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.7 ms, sys: 110 ms, total: 124 ms\n",
      "Wall time: 2.05 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = f['emb'][:100_000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b9e6b81-cf08-4834-9112-90bdb2a1a272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.7 ms, sys: 1.03 s, total: 1.05 s\n",
      "Wall time: 20.7 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = f['emb'][:1_000_000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f557639-a342-4efc-a1dd-a81936d5ffb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.6 ms, sys: 16.1 s, total: 16.1 s\n",
      "Wall time: 3min 10s\n"
     ]
    }
   ],
   "source": [
    "%time _ = f['emb'][:9_000_000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "158075b1-0d5f-47ab-bfea-933f0eb58d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 211 ms, sys: 14.5 s, total: 14.7 s\n",
      "Wall time: 4min 4s\n"
     ]
    }
   ],
   "source": [
    "%time pred_data = f['emb'][:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ba51a2-f28a-41a5-a39c-a57e767adeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86931282-053f-48fb-8912-4cc094191088",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time test_mem = f['emb'][random_idxs, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3800a381-d6c5-4d73-ad15-b5b78b4bd7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(PCG64)\n",
      "CPU times: user 1.22 s, sys: 388 ms, total: 1.61 s\n",
      "Wall time: 8.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rng = np.random.default_rng(2023)\n",
    "print(rng)\n",
    "random_pivots = rng.choice(range(10_000_000), size=(1_000), replace=False)\n",
    "pivot_indexes = np.sort(random_pivots)\n",
    "pivot_data = f['emb'][pivot_indexes, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "645d86c4-e7eb-47d8-a553-65e06ba4354c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 768)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "10f9b234-3d36-48ea-a659-2e5916962ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import gc\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def pairwise_cosine(x, y):\n",
    "    r = cosine_similarity(x, y)\n",
    "    print(r)\n",
    "    return 1-cosine_similarity(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad3c1002-9eab-4859-857f-3a28c1eadd9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'unsqueeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-302b8ea9f9c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpivot_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'unsqueeze'"
     ]
    }
   ],
   "source": [
    "pivot_data[0].unsqueeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56dc249f-5ec7-4f75-9e26-27cb26d61432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 768)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "df63b099-586a-46eb-915d-d9f9257d01fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1000)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc95cc08-bf07-4d85-a111-362429022e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 768)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "73085c93-403c-4fce-981a-1ce6279e4bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 768), dtype=float64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = np.empty((0,768))\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1010d054-2b0e-4f02-af3a-f81031456167",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dists_all = np.empty((0,1000))\n",
    "training_data = np.empty((0,768))\n",
    "prev = 0\n",
    "\n",
    "for batch, pivot in tqdm(zip(range(10_000, 10_000_000, 10_000), pivot_data)):\n",
    "    loaded_data = f['emb'][prev:batch, :]\n",
    "    dists = np.argsort(cosine_similarity([pivot], loaded_data)[0])\n",
    "    training_data_indexes = dists[-1000:]\n",
    "    # take the 1000 most similar (argsort sorts from lowest to highest)\n",
    "    dists_all = np.vstack((dists_all, prev+training_data_indexes))\n",
    "    training_data = np.vstack((training_data, loaded_data[training_data_indexes]))\n",
    "    del loaded_data\n",
    "    gc.collect()\n",
    "    prev = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c488738c-f190-476a-819f-d941ff979b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999000, 768)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea67db6e-baa6-4b9f-962a-86ac32f96728",
   "metadata": {},
   "outputs": [],
   "source": [
    "[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a4ad4a58-5403-4be5-bc8b-3e85ad302cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 106 ms, sys: 2.27 ms, total: 108 ms\n",
      "Wall time: 121 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "labels = np.array([np.array([i for j in range(1000)]) for i in range(999)])\n",
    "labels = labels.reshape(labels.shape[0]*labels.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8dff26fd-57ca-49ee-9c8d-ff178b3f0b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1000)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f6cb80e1-121c-4a54-bd84-d4a9f500feab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "def get_device() -> torch.device:\n",
    "    \"\"\" Gets the `device` to be used by torch.\n",
    "    This arugment is needed to operate with the PyTorch model instance.\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "    torch.device\n",
    "        Device\n",
    "    \"\"\"\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device('cuda:0' if use_cuda else 'cpu')\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    return device\n",
    "\n",
    "\n",
    "def data_X_to_torch(data) -> torch.FloatTensor:\n",
    "    \"\"\" Creates torch training data.\"\"\"\n",
    "    data_X = torch.from_numpy(np.array(data).astype(np.float32))\n",
    "    return data_X\n",
    "\n",
    "\n",
    "def data_to_torch(data, labels) -> Tuple[torch.FloatTensor, torch.LongTensor]:\n",
    "    \"\"\" Creates torch training data and labels.\"\"\"\n",
    "    data_X = data_X_to_torch(data)\n",
    "    data_y = torch.as_tensor(torch.from_numpy(labels), dtype=torch.long)\n",
    "    return data_X, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4d8c8b0f-aac1-4b31-8109-3589982a4142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim=768, output_dim=1000):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "          torch.nn.Linear(input_dim, 128),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        outputs = self.layers(x)\n",
    "        return outputs\n",
    "\n",
    "model = Model()\n",
    "lr = 0.01\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6d8fbff9-f17b-4173-b64d-b61ddaf4e115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 756 ms, sys: 741 ms, total: 1.5 s\n",
      "Wall time: 1.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([999000, 768]), torch.Size([999000]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data_X, data_y = data_to_torch(training_data, labels)\n",
    "data_X.shape, data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8a0309cb-0fff-4006-bd74-757e8ab769f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    data_X: torch.FloatTensor,\n",
    "    data_y: torch.LongTensor,\n",
    "    model,\n",
    "    optimizer,\n",
    "    device,\n",
    "    epochs=500,\n",
    "):\n",
    "    step = data_X.shape[0] // epochs // 10\n",
    "    losses = []\n",
    "    for ep in range(epochs):\n",
    "        if ep % step == 0 and ep != 0:\n",
    "            print(f'{time.time()} | Epoch {ep} | Loss {curr_loss.item()}')\n",
    "        pred_y = model(data_X.to(device))\n",
    "        curr_loss = loss(pred_y, data_y.to(device))\n",
    "        losses.append(curr_loss.item())\n",
    "\n",
    "        model.zero_grad()\n",
    "        curr_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    return losses, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "eaca812c-be5b-49a6-80f9-898706a8f81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(PCG64)\n",
      "CPU times: user 99 ms, sys: 39.6 ms, total: 139 ms\n",
      "Wall time: 139 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rng_offset = 1\n",
    "rng = np.random.default_rng(2023+rng_offset)\n",
    "rng_offset += 1\n",
    "print(rng)\n",
    "random_idxs = rng.choice(range(999000), size=(10_000), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d1cf2ef9-1919-4af0-9a66-4e21347f672a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 768]), torch.Size([10000]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X_s = data_X[random_idxs]\n",
    "data_y_s = data_y[random_idxs]\n",
    "data_X_s.shape, data_y_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "efe09d5f-2517-49d0-bb89-58b3f7d39ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(output_dim=np.unique(data_y_s).shape[0])\n",
    "lr = 0.1\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cc6b9796-63e8-47e6-98f9-ceace5321e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n",
      "Epoch 20\n",
      "Epoch 30\n",
      "Epoch 40\n",
      "Epoch 50\n",
      "Epoch 60\n",
      "Epoch 70\n",
      "Epoch 80\n",
      "Epoch 90\n",
      "CPU times: user 55.6 s, sys: 2.76 s, total: 58.3 s\n",
      "Wall time: 59.8 s\n"
     ]
    }
   ],
   "source": [
    "%time losses, model = train(data_X_s, data_y_s, model, optimizer, device, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5ba8d7d2-5088-4055-9598-ee17f1df375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict( model, device, data_X: torch.FloatTensor):\n",
    "    \"\"\" Collects predictions for multiple data points (used in structure building).\"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_outputs = torch.tensor([], device=device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(data_X.to(device))\n",
    "        all_outputs = torch.cat((all_outputs, outputs), 0)\n",
    "\n",
    "    _, y_pred = torch.max(all_outputs, 1)\n",
    "    return y_pred.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1a840121-5d96-4bfc-abb4-ed8790193a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(model, device, data_X_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5ecde9c7-bde4-4bec-b883-551d26ca28d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([515, 589, 280,  ..., 141, 934,  88])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "feb68c1a-8ea6-4cbf-8670-8ac612022cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([515, 589, 280, ..., 141, 934,  88])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9045ca-7f86-474e-b552-388c2ad2078a",
   "metadata": {},
   "source": [
    "### we can let go of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "35b6d369-fb24-4c33-ba8b-ade48abbc654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del training_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83a2340-5091-42bd-8fd8-9c5d28365acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load everyting and then filter out whatever\n",
    "%time pred_data = f['emb'][:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "555b0de2-7793-43f9-9fc5-897b0849830d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 306 ms, sys: 367 ms, total: 672 ms\n",
      "Wall time: 813 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9001000,)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "predict_indexes = np.setdiff1d(np.arange(0, 10_000_000), dists_all.flatten())\n",
    "predict_indexes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3ae6c328-2f39-43af-96ec-7e48ed9ca62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 102 ms, sys: 67.5 ms, total: 170 ms\n",
      "Wall time: 172 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9001000,)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "predict_indexes = np.sort(predict_indexes)\n",
    "predict_indexes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "1dd2ed66-9994-4523-bbd4-b4b90a26a04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_indexes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d00637-3d3d-423c-84e9-0e06651528d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "loaded_pred_data = f['emb'][predict_indexes, :]\n",
    "loaded_pred_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddff82b1-7ad0-4f14-afce-3d0fb8fb3645",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_pred_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2e892d01-4999-4614-b803-8fd549c89ef2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "maximum supported dimension for an ndarray is 32, found 1000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-f6d1fa8d2aa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdists_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdists_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdists_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: maximum supported dimension for an ndarray is 32, found 1000"
     ]
    }
   ],
   "source": [
    "dists_all.reshape((dists_all[0]*dists_all[1]))#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ccc26f-46da-4f66-b5dc-c40d4db7fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def predict(self, data_X: torch.FloatTensor):\n",
    "        \"\"\" Collects predictions for multiple data points (used in structure building).\"\"\"\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        all_outputs = torch.tensor([], device=self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(data_X.to(self.device))\n",
    "            all_outputs = torch.cat((all_outputs, outputs), 0)\n",
    "\n",
    "        _, y_pred = torch.max(all_outputs, 1)\n",
    "        return np.array([self.model.output_neurons[label] for label in y_pred.cpu().numpy()])\n",
    "\n",
    "    def predict_single(self, data_X: torch.FloatTensor):\n",
    "        \"\"\" Collects predictions for a single data point (used in query predictions).\"\"\"\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(data_X.to(self.device))\n",
    "\n",
    "        prob = nnf.softmax(outputs, dim=0)\n",
    "        top_prob, top_class = prob.topk(self.model.n_output_neurons, dim=0)\n",
    "        top_prob = top_prob.cpu().numpy()\n",
    "        return top_prob, np.array([self.model.output_neurons[label] for label in top_class.cpu().numpy()])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
