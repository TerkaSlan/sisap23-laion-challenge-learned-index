{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2cdb38d-1cd3-4dcc-8a60-2ec8e6f05ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33bb801b-9571-45d9-8de2-cb8bdf971c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.21 ms, sys: 0 ns, total: 1.21 ms\n",
      "Wall time: 3.75 ms\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "data_path = 'data/pca32v2/10M/dataset.h5'\n",
    "%time f = h5py.File(data_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eea08abe-1263-427e-a3b7-b42adf1d5599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 1.01 s, total: 1.01 s\n",
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "data_path = 'data/clip768v2/10M/dataset.h5'\n",
    "%time f = h5py.File(data_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "170d527d-dd1b-4716-9454-0829de3292cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10120191"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f['emb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313af20e-7ac3-4002-afc9-9b72773b5652",
   "metadata": {},
   "source": [
    "## Goal:\n",
    "1) load data for training (1000*1000 objects)\n",
    "2) train, predict on train, dispose of the training data (keep ids)\n",
    "3) load data for predict (rest 9M objects)\n",
    "4) predict, dispose of the data (keep ids)\n",
    "5) on search, load the data in the visited bucket again (10k objects on avg), compute distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9d370de-5925-4326-9743-03dc399e2df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.1 ms, sys: 1.34 s, total: 1.36 s\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "%time loaded_data = f['pca32'][:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8effd8a-9ce8-4b3b-b325-5c2d565ecda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 686 µs, sys: 0 ns, total: 686 µs\n",
      "Wall time: 1.12 ms\n",
      "CPU times: user 0 ns, sys: 618 ms, total: 618 ms\n",
      "Wall time: 639 ms\n"
     ]
    }
   ],
   "source": [
    "data_path_32 = 'data/pca32v2/10M/dataset.h5'\n",
    "%time f = h5py.File(data_path_32, 'r')\n",
    "%time loaded_data_pca = f['pca32'][:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06fb66c8-ef44-4dcf-9b01-27e0d6eb3306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from li.BulkLMI import BulkLMI\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c09397e0-68f3-40d8-abd5-6eba339abcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(loaded_data)\n",
    "data.index += 1\n",
    "data_s = data.sample(5_000_000, random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aff14d57-ddcb-465d-b3ec-43887bac6df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 985 ms, sys: 386 ms, total: 1.37 s\n",
      "Wall time: 1.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "blmi = BulkLMI()\n",
    "blmi.insert(data_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b63f7652-5362-4be7-a42b-a5335c2438f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='[%(asctime)s][%(levelname)-5.5s][%(name)-.20s] %(message)s'\n",
    ")\n",
    "LOG = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6e5b1e5-ae5e-40f7-87cb-7d233aaaad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = LogisticRegression(random_state=0).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a74cd039-5622-45bf-a9d7-bc4184f71bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-01 12:21:27,678][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0,)\n",
      "[2023-07-01 12:21:32,973][INFO ][numexpr.utils] Note: detected 112 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "[2023-07-01 12:21:32,977][INFO ][numexpr.utils] Note: NumExpr detected 112 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.6 s, sys: 4.71 s, total: 57.3 s\n",
      "Wall time: 59.1 s\n"
     ]
    }
   ],
   "source": [
    "info_df = pd.DataFrame([], columns=['op', 'time-taken', 'size', '#-objects'])\n",
    "%time info_df = blmi.deepen(blmi.nodes[(0, )], 100, info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dda9079-07db-4fdb-a6ae-e401fd981c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-01 12:22:27,203][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 0)\n",
      "[2023-07-01 12:22:27,913][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 1)\n",
      "[2023-07-01 12:22:28,472][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 2)\n",
      "[2023-07-01 12:22:29,398][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 3)\n",
      "[2023-07-01 12:22:30,167][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 4)\n",
      "[2023-07-01 12:22:30,729][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 5)\n",
      "[2023-07-01 12:22:31,663][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 6)\n",
      "[2023-07-01 12:22:32,361][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 7)\n",
      "[2023-07-01 12:22:32,997][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 8)\n",
      "[2023-07-01 12:22:33,509][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 9)\n",
      "[2023-07-01 12:22:34,231][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 10)\n",
      "[2023-07-01 12:22:34,777][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 11)\n",
      "[2023-07-01 12:22:35,689][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 12)\n",
      "[2023-07-01 12:22:36,602][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 13)\n",
      "[2023-07-01 12:22:37,276][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 14)\n",
      "[2023-07-01 12:22:38,054][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 15)\n",
      "[2023-07-01 12:22:38,704][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 16)\n",
      "[2023-07-01 12:22:39,447][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 17)\n",
      "[2023-07-01 12:22:40,216][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 18)\n",
      "[2023-07-01 12:22:41,453][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 19)\n",
      "[2023-07-01 12:22:42,111][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 20)\n",
      "[2023-07-01 12:22:42,889][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 21)\n",
      "[2023-07-01 12:22:43,638][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 22)\n",
      "[2023-07-01 12:22:44,313][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 23)\n",
      "[2023-07-01 12:22:45,128][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 24)\n",
      "[2023-07-01 12:22:45,939][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 25)\n",
      "[2023-07-01 12:22:46,746][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 26)\n",
      "[2023-07-01 12:22:47,542][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 27)\n",
      "[2023-07-01 12:22:48,559][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 28)\n",
      "[2023-07-01 12:22:49,362][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 29)\n",
      "[2023-07-01 12:22:50,034][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 30)\n",
      "[2023-07-01 12:22:50,830][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 31)\n",
      "[2023-07-01 12:22:51,535][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 32)\n",
      "[2023-07-01 12:22:52,275][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 33)\n",
      "[2023-07-01 12:22:53,381][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 34)\n",
      "[2023-07-01 12:22:54,145][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 35)\n",
      "[2023-07-01 12:22:55,051][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 36)\n",
      "[2023-07-01 12:22:55,910][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 37)\n",
      "[2023-07-01 12:22:56,870][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 38)\n",
      "[2023-07-01 12:22:57,586][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 39)\n",
      "[2023-07-01 12:22:58,800][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 40)\n",
      "[2023-07-01 12:22:59,612][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 41)\n",
      "[2023-07-01 12:23:00,421][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 42)\n",
      "[2023-07-01 12:23:01,203][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 43)\n",
      "[2023-07-01 12:23:02,431][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 44)\n",
      "[2023-07-01 12:23:03,204][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 45)\n",
      "[2023-07-01 12:23:04,124][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 46)\n",
      "[2023-07-01 12:23:04,944][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 47)\n",
      "[2023-07-01 12:23:06,488][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 48)\n",
      "[2023-07-01 12:23:07,432][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 49)\n",
      "[2023-07-01 12:23:08,469][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 50)\n",
      "[2023-07-01 12:23:09,777][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 51)\n",
      "[2023-07-01 12:23:11,060][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 52)\n",
      "[2023-07-01 12:23:12,021][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 53)\n",
      "[2023-07-01 12:23:13,051][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 54)\n",
      "[2023-07-01 12:23:13,875][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 55)\n",
      "[2023-07-01 12:23:15,024][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 56)\n",
      "[2023-07-01 12:23:16,159][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 57)\n",
      "[2023-07-01 12:23:17,361][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 58)\n",
      "[2023-07-01 12:23:18,651][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 59)\n",
      "[2023-07-01 12:23:19,612][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 60)\n",
      "[2023-07-01 12:23:20,417][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 61)\n",
      "[2023-07-01 12:23:21,823][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 62)\n",
      "[2023-07-01 12:23:22,621][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 63)\n",
      "[2023-07-01 12:23:23,460][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 64)\n",
      "[2023-07-01 12:23:24,754][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 65)\n",
      "[2023-07-01 12:23:25,614][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 66)\n",
      "[2023-07-01 12:23:26,487][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 67)\n",
      "[2023-07-01 12:23:27,820][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 68)\n",
      "[2023-07-01 12:23:28,896][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 69)\n",
      "[2023-07-01 12:23:29,994][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 70)\n",
      "[2023-07-01 12:23:31,301][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 71)\n",
      "[2023-07-01 12:23:32,412][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 72)\n",
      "[2023-07-01 12:23:33,691][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 73)\n",
      "[2023-07-01 12:23:34,689][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 74)\n",
      "[2023-07-01 12:23:35,825][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 75)\n",
      "[2023-07-01 12:23:37,383][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 76)\n",
      "[2023-07-01 12:23:38,389][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 77)\n",
      "[2023-07-01 12:23:39,674][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 78)\n",
      "[2023-07-01 12:23:40,790][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 79)\n",
      "[2023-07-01 12:23:41,957][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 80)\n",
      "[2023-07-01 12:23:43,296][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 81)\n",
      "[2023-07-01 12:23:44,419][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 82)\n",
      "[2023-07-01 12:23:45,739][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 83)\n",
      "[2023-07-01 12:23:46,719][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 84)\n",
      "[2023-07-01 12:23:48,044][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 85)\n",
      "[2023-07-01 12:23:48,965][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 86)\n",
      "[2023-07-01 12:23:50,373][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 87)\n",
      "[2023-07-01 12:23:51,385][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 88)\n",
      "[2023-07-01 12:23:52,924][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 89)\n",
      "[2023-07-01 12:23:54,126][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 90)\n",
      "[2023-07-01 12:23:55,165][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 91)\n",
      "[2023-07-01 12:23:56,780][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 92)\n",
      "[2023-07-01 12:23:57,934][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 93)\n",
      "[2023-07-01 12:23:59,362][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 94)\n",
      "[2023-07-01 12:24:00,377][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 95)\n",
      "[2023-07-01 12:24:02,113][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 96)\n",
      "[2023-07-01 12:24:03,642][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 97)\n",
      "[2023-07-01 12:24:04,752][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 98)\n",
      "[2023-07-01 12:24:06,586][INFO ][li.BulkLMI.BulkLMI] ==== Deepen with (0, 99)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 37s, sys: 1.06 s, total: 1min 38s\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, leaf in enumerate(blmi.get_leaf_nodes_pos()):\n",
    "    info_df = blmi.deepen(\n",
    "        blmi.nodes[leaf],\n",
    "        100,\n",
    "        info_df\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01dca161-1ac2-435d-aa19-f8acc28b9604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>children</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0,)</th>\n",
       "      <td>InnerNode</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 0)</th>\n",
       "      <td>InnerNode</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 0, 0)</th>\n",
       "      <td>LeafNode</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 0, 1)</th>\n",
       "      <td>LeafNode</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 0, 2)</th>\n",
       "      <td>LeafNode</td>\n",
       "      <td>1336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 99, 95)</th>\n",
       "      <td>LeafNode</td>\n",
       "      <td>854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 99, 96)</th>\n",
       "      <td>LeafNode</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 99, 97)</th>\n",
       "      <td>LeafNode</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 99, 98)</th>\n",
       "      <td>LeafNode</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 99, 99)</th>\n",
       "      <td>LeafNode</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10101 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  type children\n",
       "key                            \n",
       "(0,)         InnerNode      100\n",
       "(0, 0)       InnerNode      100\n",
       "(0, 0, 0)     LeafNode      344\n",
       "(0, 0, 1)     LeafNode      361\n",
       "(0, 0, 2)     LeafNode     1336\n",
       "...                ...      ...\n",
       "(0, 99, 95)   LeafNode      854\n",
       "(0, 99, 96)   LeafNode      321\n",
       "(0, 99, 97)   LeafNode      381\n",
       "(0, 99, 98)   LeafNode      312\n",
       "(0, 99, 99)   LeafNode      393\n",
       "\n",
       "[10101 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blmi.dump_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baba9978-3e50-4ae8-af7b-9a1e5f34141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6144796-d80a-4784-a0ab-6c8a37beb3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5120191, 32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_insert = data.loc[np.setdiff1d(data.index, data_s.index)]\n",
    "#blmi.insert(data_to_insert)\n",
    "data_to_insert.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94541aba-cb73-4957-9196-a449fd9a3a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 s, sys: 4.36 s, total: 19.6 s\n",
      "Wall time: 20.1 s\n"
     ]
    }
   ],
   "source": [
    "%time blmi.insert(data_to_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3590527-c9c5-4abb-8c72-ab2091ad9088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>children</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0,)</th>\n",
       "      <td>InnerNode</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 0)</th>\n",
       "      <td>InnerNode</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 0, 0)</th>\n",
       "      <td>LeafNode</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 0, 1)</th>\n",
       "      <td>LeafNode</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 0, 2)</th>\n",
       "      <td>LeafNode</td>\n",
       "      <td>2605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 99, 95)</th>\n",
       "      <td>LeafNode</td>\n",
       "      <td>1765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 99, 96)</th>\n",
       "      <td>LeafNode</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 99, 97)</th>\n",
       "      <td>LeafNode</td>\n",
       "      <td>811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 99, 98)</th>\n",
       "      <td>LeafNode</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 99, 99)</th>\n",
       "      <td>LeafNode</td>\n",
       "      <td>782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10101 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  type children\n",
       "key                            \n",
       "(0,)         InnerNode      100\n",
       "(0, 0)       InnerNode      100\n",
       "(0, 0, 0)     LeafNode      711\n",
       "(0, 0, 1)     LeafNode      723\n",
       "(0, 0, 2)     LeafNode     2605\n",
       "...                ...      ...\n",
       "(0, 99, 95)   LeafNode     1765\n",
       "(0, 99, 96)   LeafNode      701\n",
       "(0, 99, 97)   LeafNode      811\n",
       "(0, 99, 98)   LeafNode      686\n",
       "(0, 99, 99)   LeafNode      782\n",
       "\n",
       "[10101 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blmi.dump_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0abf394e-ef1e-4fcc-ad2a-f0b4100a0299",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'data/clip768v2/10M/'\n",
    "base_path = 'data/pca32v2/10M/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67f801b8-b06d-4792-be91-7aa46bd8ed74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 3.22 ms, total: 3.22 ms\n",
      "Wall time: 20.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "queries_path = f'{base_path}/query.h5'\n",
    "f2 = h5py.File(queries_path, 'r')\n",
    "#loaded_queries = f2['emb'][:, :]\n",
    "loaded_queries = f2['pca32'][:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2895d5a-b7c6-4102-b128-daf4a963e7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error',)).History will not be written to the database.\n",
      "CPU times: user 0 ns, sys: 6.7 ms, total: 6.7 ms\n",
      "Wall time: 52.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gt_path = f'data/groundtruth-10M.h5'\n",
    "f3 = h5py.File(gt_path, 'r')\n",
    "loaded_gt = f3['knns'][:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f3d2c1f-eed1-48fc-b47b-1b35c75ba3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from li.utils import pairwise_cosine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6b8597a-b253-4c6e-8ce9-23516a4d3e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_max_recursion_limit():\n",
    "    \"\"\" Increases the maximum recursion limit.\n",
    "    Source: https://stackoverflow.com/a/16248113\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    import resource\n",
    "    resource.setrlimit(resource.RLIMIT_STACK, (2**29, -1))\n",
    "    sys.setrecursionlimit(10**6)\n",
    "increase_max_recursion_limit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b93171d6-a9b6-40e0-886c-4fe7ac3b2f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 592 ms, sys: 67.6 ms, total: 660 ms\n",
      "Wall time: 679 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res_all = []\n",
    "for i, query in tqdm(enumerate(loaded_queries)):\n",
    "    pred_leaf_nodes = blmi.search(query, stop_condition=1_000_000)[0]\n",
    "    object_ids = []\n",
    "    for pred_leaf_node in pred_leaf_nodes:\n",
    "        leaf_node = blmi.nodes.get(pred_leaf_node)\n",
    "        if leaf_node is not None:\n",
    "            object_ids.extend(leaf_node.object_ids)\n",
    "\n",
    "    #bucket_ids = [[i, mapping[bucket]] for bucket in blmi.search(query, stop_condition=500)[0]]\n",
    "    dists = pairwise_cosine([query], data.loc[object_ids])\n",
    "    break\n",
    "    res_all.extend(bucket_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "078ed641-ed2f-4b92-a86b-a1ea3d9f03ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001425"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(object_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "792215e2-0f3f-4a5c-b0a3-9987cd7eaacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 638 µs, sys: 57 µs, total: 695 µs\n",
      "Wall time: 3.95 ms\n",
      "CPU times: user 20.8 ms, sys: 16 s, total: 16.1 s\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "data_path = 'data/clip768v2/10M/dataset.h5'\n",
    "%time f = h5py.File(data_path, 'r')\n",
    "%time loaded_clip_data = f['emb'][:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88fda68a-b187-4320-85e3-32980a94c141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10120191, 768)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_clip_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18f4965d-5f59-4bb3-8a15-2c7d4605d615",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data = pd.DataFrame(loaded_clip_data)\n",
    "seq_data.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0eb26659-7a8d-4321-b242-00fee0856975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 33.5 ms, total: 33.5 ms\n",
      "Wall time: 291 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_path = 'data/clip768v2/10M/'\n",
    "queries_path = f'{base_path}/query.h5'\n",
    "f2 = h5py.File(queries_path, 'r')\n",
    "#loaded_queries = f2['emb'][:, :]\n",
    "loaded_queries_seq = f2['emb'][:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe10f21b-b41b-4ff7-affb-e55b72ac51bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.12 s, sys: 6.01 s, total: 12.1 s\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "%time dists = pairwise_cosine([loaded_queries_seq[0]], seq_data.loc[object_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e50d82b-a06e-4a87-bb9e-4bb23aa30a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76355c4c-79ff-443f-997f-bbf306ec568d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1831320,\n",
       " 7535354,\n",
       " 7059014,\n",
       " 7563483,\n",
       " 3003515,\n",
       " 5278218,\n",
       " 8190596,\n",
       " 9060635,\n",
       " 210839,\n",
       " 5805329]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[object_ids].index[np.argsort(dists)[:, :k][0]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42bbbf99-da0a-4982-83e7-40b281ef9337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1831320, 7535354, 7059014, 7563483, 3003515, 5278218, 8190596,\n",
       "       9060635, 5509896,  210839], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_gt[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d403d76-0399-4437-a0c7-bcabd4af5edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.intersect1d(\n",
    "    loaded_gt[0][:10],\n",
    "    np.array(data.loc[object_ids].index[np.argsort(dists)[:, :k][0]])[:10]\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111e8bf-4164-443c-86fb-04accf15e23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "349053c1-d67b-4aec-8582-01ac2d90ed45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.23 ms, sys: 14.3 ms, total: 17.5 ms\n",
      "Wall time: 372 ms\n"
     ]
    }
   ],
   "source": [
    "%time loaded_data = f['emb'][:10_000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08192e49-5914-46f6-b3e3-c9e409240d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.22 s, sys: 284 ms, total: 1.51 s\n",
      "Wall time: 1.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "rng = np.random.default_rng(2023)\n",
    "random_idxs = rng.choice(range(10_000_000), size=(10_000), replace=False)\n",
    "random_idxs = np.sort(random_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "073aa7c4-9dba-494e-b7bb-cc623250c17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.17 s, sys: 784 ms, total: 2.95 s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%time loaded_data = f['emb'][random_idxs, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bc10f6c-3ecc-4666-b4d3-a262969b254b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.7 ms, sys: 110 ms, total: 124 ms\n",
      "Wall time: 2.05 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = f['emb'][:100_000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b9e6b81-cf08-4834-9112-90bdb2a1a272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.7 ms, sys: 1.03 s, total: 1.05 s\n",
      "Wall time: 20.7 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = f['emb'][:1_000_000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f557639-a342-4efc-a1dd-a81936d5ffb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.6 ms, sys: 16.1 s, total: 16.1 s\n",
      "Wall time: 3min 10s\n"
     ]
    }
   ],
   "source": [
    "%time _ = f['emb'][:9_000_000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "158075b1-0d5f-47ab-bfea-933f0eb58d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 211 ms, sys: 14.5 s, total: 14.7 s\n",
      "Wall time: 4min 4s\n"
     ]
    }
   ],
   "source": [
    "%time pred_data = f['emb'][:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ba51a2-f28a-41a5-a39c-a57e767adeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86931282-053f-48fb-8912-4cc094191088",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time test_mem = f['emb'][random_idxs, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3800a381-d6c5-4d73-ad15-b5b78b4bd7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(PCG64)\n",
      "CPU times: user 1.22 s, sys: 388 ms, total: 1.61 s\n",
      "Wall time: 8.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rng = np.random.default_rng(2023)\n",
    "print(rng)\n",
    "random_pivots = rng.choice(range(10_000_000), size=(1_000), replace=False)\n",
    "pivot_indexes = np.sort(random_pivots)\n",
    "pivot_data = f['emb'][pivot_indexes, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "645d86c4-e7eb-47d8-a553-65e06ba4354c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 768)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "10f9b234-3d36-48ea-a659-2e5916962ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import gc\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def pairwise_cosine(x, y):\n",
    "    r = cosine_similarity(x, y)\n",
    "    print(r)\n",
    "    return 1-cosine_similarity(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad3c1002-9eab-4859-857f-3a28c1eadd9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'unsqueeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-302b8ea9f9c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpivot_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'unsqueeze'"
     ]
    }
   ],
   "source": [
    "pivot_data[0].unsqueeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56dc249f-5ec7-4f75-9e26-27cb26d61432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 768)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "df63b099-586a-46eb-915d-d9f9257d01fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1000)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc95cc08-bf07-4d85-a111-362429022e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 768)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "73085c93-403c-4fce-981a-1ce6279e4bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 768), dtype=float64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = np.empty((0,768))\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1010d054-2b0e-4f02-af3a-f81031456167",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dists_all = np.empty((0,1000))\n",
    "training_data = np.empty((0,768))\n",
    "prev = 0\n",
    "\n",
    "for batch, pivot in tqdm(zip(range(10_000, 10_000_000, 10_000), pivot_data)):\n",
    "    loaded_data = f['emb'][prev:batch, :]\n",
    "    dists = np.argsort(cosine_similarity([pivot], loaded_data)[0])\n",
    "    training_data_indexes = dists[-1000:]\n",
    "    # take the 1000 most similar (argsort sorts from lowest to highest)\n",
    "    dists_all = np.vstack((dists_all, prev+training_data_indexes))\n",
    "    training_data = np.vstack((training_data, loaded_data[training_data_indexes]))\n",
    "    del loaded_data\n",
    "    gc.collect()\n",
    "    prev = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c488738c-f190-476a-819f-d941ff979b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999000, 768)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea67db6e-baa6-4b9f-962a-86ac32f96728",
   "metadata": {},
   "outputs": [],
   "source": [
    "[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a4ad4a58-5403-4be5-bc8b-3e85ad302cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 106 ms, sys: 2.27 ms, total: 108 ms\n",
      "Wall time: 121 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "labels = np.array([np.array([i for j in range(1000)]) for i in range(999)])\n",
    "labels = labels.reshape(labels.shape[0]*labels.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8dff26fd-57ca-49ee-9c8d-ff178b3f0b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1000)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f6cb80e1-121c-4a54-bd84-d4a9f500feab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "def get_device() -> torch.device:\n",
    "    \"\"\" Gets the `device` to be used by torch.\n",
    "    This arugment is needed to operate with the PyTorch model instance.\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "    torch.device\n",
    "        Device\n",
    "    \"\"\"\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device('cuda:0' if use_cuda else 'cpu')\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    return device\n",
    "\n",
    "\n",
    "def data_X_to_torch(data) -> torch.FloatTensor:\n",
    "    \"\"\" Creates torch training data.\"\"\"\n",
    "    data_X = torch.from_numpy(np.array(data).astype(np.float32))\n",
    "    return data_X\n",
    "\n",
    "\n",
    "def data_to_torch(data, labels) -> Tuple[torch.FloatTensor, torch.LongTensor]:\n",
    "    \"\"\" Creates torch training data and labels.\"\"\"\n",
    "    data_X = data_X_to_torch(data)\n",
    "    data_y = torch.as_tensor(torch.from_numpy(labels), dtype=torch.long)\n",
    "    return data_X, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4d8c8b0f-aac1-4b31-8109-3589982a4142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim=768, output_dim=1000):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "          torch.nn.Linear(input_dim, 128),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        outputs = self.layers(x)\n",
    "        return outputs\n",
    "\n",
    "model = Model()\n",
    "lr = 0.01\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6d8fbff9-f17b-4173-b64d-b61ddaf4e115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 756 ms, sys: 741 ms, total: 1.5 s\n",
      "Wall time: 1.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([999000, 768]), torch.Size([999000]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data_X, data_y = data_to_torch(training_data, labels)\n",
    "data_X.shape, data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8a0309cb-0fff-4006-bd74-757e8ab769f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    data_X: torch.FloatTensor,\n",
    "    data_y: torch.LongTensor,\n",
    "    model,\n",
    "    optimizer,\n",
    "    device,\n",
    "    epochs=500,\n",
    "):\n",
    "    step = data_X.shape[0] // epochs // 10\n",
    "    losses = []\n",
    "    for ep in range(epochs):\n",
    "        if ep % step == 0 and ep != 0:\n",
    "            print(f'{time.time()} | Epoch {ep} | Loss {curr_loss.item()}')\n",
    "        pred_y = model(data_X.to(device))\n",
    "        curr_loss = loss(pred_y, data_y.to(device))\n",
    "        losses.append(curr_loss.item())\n",
    "\n",
    "        model.zero_grad()\n",
    "        curr_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    return losses, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "eaca812c-be5b-49a6-80f9-898706a8f81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(PCG64)\n",
      "CPU times: user 99 ms, sys: 39.6 ms, total: 139 ms\n",
      "Wall time: 139 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rng_offset = 1\n",
    "rng = np.random.default_rng(2023+rng_offset)\n",
    "rng_offset += 1\n",
    "print(rng)\n",
    "random_idxs = rng.choice(range(999000), size=(10_000), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d1cf2ef9-1919-4af0-9a66-4e21347f672a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 768]), torch.Size([10000]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X_s = data_X[random_idxs]\n",
    "data_y_s = data_y[random_idxs]\n",
    "data_X_s.shape, data_y_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "efe09d5f-2517-49d0-bb89-58b3f7d39ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(output_dim=np.unique(data_y_s).shape[0])\n",
    "lr = 0.1\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cc6b9796-63e8-47e6-98f9-ceace5321e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n",
      "Epoch 20\n",
      "Epoch 30\n",
      "Epoch 40\n",
      "Epoch 50\n",
      "Epoch 60\n",
      "Epoch 70\n",
      "Epoch 80\n",
      "Epoch 90\n",
      "CPU times: user 55.6 s, sys: 2.76 s, total: 58.3 s\n",
      "Wall time: 59.8 s\n"
     ]
    }
   ],
   "source": [
    "%time losses, model = train(data_X_s, data_y_s, model, optimizer, device, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5ba8d7d2-5088-4055-9598-ee17f1df375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict( model, device, data_X: torch.FloatTensor):\n",
    "    \"\"\" Collects predictions for multiple data points (used in structure building).\"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_outputs = torch.tensor([], device=device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(data_X.to(device))\n",
    "        all_outputs = torch.cat((all_outputs, outputs), 0)\n",
    "\n",
    "    _, y_pred = torch.max(all_outputs, 1)\n",
    "    return y_pred.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1a840121-5d96-4bfc-abb4-ed8790193a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(model, device, data_X_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5ecde9c7-bde4-4bec-b883-551d26ca28d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([515, 589, 280,  ..., 141, 934,  88])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "feb68c1a-8ea6-4cbf-8670-8ac612022cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([515, 589, 280, ..., 141, 934,  88])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9045ca-7f86-474e-b552-388c2ad2078a",
   "metadata": {},
   "source": [
    "### we can let go of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "35b6d369-fb24-4c33-ba8b-ade48abbc654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del training_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83a2340-5091-42bd-8fd8-9c5d28365acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load everyting and then filter out whatever\n",
    "%time pred_data = f['emb'][:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "555b0de2-7793-43f9-9fc5-897b0849830d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 306 ms, sys: 367 ms, total: 672 ms\n",
      "Wall time: 813 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9001000,)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "predict_indexes = np.setdiff1d(np.arange(0, 10_000_000), dists_all.flatten())\n",
    "predict_indexes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3ae6c328-2f39-43af-96ec-7e48ed9ca62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 102 ms, sys: 67.5 ms, total: 170 ms\n",
      "Wall time: 172 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9001000,)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "predict_indexes = np.sort(predict_indexes)\n",
    "predict_indexes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "1dd2ed66-9994-4523-bbd4-b4b90a26a04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_indexes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d00637-3d3d-423c-84e9-0e06651528d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "loaded_pred_data = f['emb'][predict_indexes, :]\n",
    "loaded_pred_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddff82b1-7ad0-4f14-afce-3d0fb8fb3645",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_pred_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2e892d01-4999-4614-b803-8fd549c89ef2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "maximum supported dimension for an ndarray is 32, found 1000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-f6d1fa8d2aa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdists_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdists_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdists_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: maximum supported dimension for an ndarray is 32, found 1000"
     ]
    }
   ],
   "source": [
    "dists_all.reshape((dists_all[0]*dists_all[1]))#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ccc26f-46da-4f66-b5dc-c40d4db7fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def predict(self, data_X: torch.FloatTensor):\n",
    "        \"\"\" Collects predictions for multiple data points (used in structure building).\"\"\"\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        all_outputs = torch.tensor([], device=self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(data_X.to(self.device))\n",
    "            all_outputs = torch.cat((all_outputs, outputs), 0)\n",
    "\n",
    "        _, y_pred = torch.max(all_outputs, 1)\n",
    "        return np.array([self.model.output_neurons[label] for label in y_pred.cpu().numpy()])\n",
    "\n",
    "    def predict_single(self, data_X: torch.FloatTensor):\n",
    "        \"\"\" Collects predictions for a single data point (used in query predictions).\"\"\"\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(data_X.to(self.device))\n",
    "\n",
    "        prob = nnf.softmax(outputs, dim=0)\n",
    "        top_prob, top_class = prob.topk(self.model.n_output_neurons, dim=0)\n",
    "        top_prob = top_prob.cpu().numpy()\n",
    "        return top_prob, np.array([self.model.output_neurons[label] for label in top_class.cpu().numpy()])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
